{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "6dXfml2I5mvb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73a42e8-eff5-4cc2-c3bd-b1fa53bee9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUFwPuAiOtfI",
        "outputId": "bb34c9fb-44c6-46cb-c78c-a02160a44f3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bash: line 1: syntax error near unexpected token `newline'\n",
            "bash: line 1: `<!DOCTYPE html>'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICH7Oazz-35C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c27f5be-81a5-4a35-da55-d6a636920fe8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.6.13-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (2.0.0+cu118)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.14.0-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.2/224.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (3.11.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.0 timm-0.6.13\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12xHrz1UlGUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfe7aefe-1571-4eaf-d69d-e1846c7be46d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.7.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.7.1%2Bcu101-cp39-cp39-linux_x86_64.whl (735.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m735.4/735.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.8.2%2Bcu101-cp39-cp39-linux_x86_64.whl (12.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1+cu101) (4.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch==1.7.1+cu101) (1.22.4)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision==0.8.2+cu101) (8.4.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.0+cu118\n",
            "    Uninstalling torch-2.0.0+cu118:\n",
            "      Successfully uninstalled torch-2.0.0+cu118\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.1+cu118\n",
            "    Uninstalling torchvision-0.15.1+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.1+cu118\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.7.1+cu101 which is incompatible.\n",
            "torchdata 0.6.0 requires torch==2.0.0, but you have torch 1.7.1+cu101 which is incompatible.\n",
            "torchaudio 2.0.1+cu118 requires torch==2.0.0, but you have torch 1.7.1+cu101 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.7.1+cu101 torchvision-0.8.2+cu101\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==1.7.1+cu101 torchvision==0.8.2+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-Fn4UXkRvV4"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RUVKlm3O7Ir",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2598783b-fe43-401a-a7de-0558c0968c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 6413866113429845832\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14343274496\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 5569296721905227868\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0w_RA0v2VEZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.distributed as dist\n",
        "import math\n",
        "\n",
        "\n",
        "class RASampler(torch.utils.data.Sampler):\n",
        "    \"\"\"Sampler that restricts data loading to a subset of the dataset for distributed,\n",
        "    with repeated augmentation.\n",
        "    It ensures that different each augmented version of a sample will be visible to a\n",
        "    different process (GPU)\n",
        "    Heavily based on torch.utils.data.DistributedSampler\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, num_replicas=None, rank=None, shuffle=True):\n",
        "        # if num_replicas is None:\n",
        "        #     if not dist.is_available():\n",
        "        #         raise RuntimeError(\"Requires distributed package to be available\")\n",
        "        #     num_replicas = dist.get_world_size()\n",
        "        # if rank is None:\n",
        "        #     if not dist.is_available():\n",
        "        #         raise RuntimeError(\"Requires distributed package to be available\")\n",
        "        #     rank = dist.get_rank()\n",
        "        self.dataset = dataset\n",
        "        self.num_replicas = num_replicas\n",
        "        # self.rank = rank\n",
        "        self.epoch = 0\n",
        "        self.num_samples = int(math.ceil(len(self.dataset) * 3.0 / self.num_replicas))\n",
        "        self.total_size = self.num_samples * self.num_replicas\n",
        "        # self.num_selected_samples = int(math.ceil(len(self.dataset) / self.num_replicas))\n",
        "        self.num_selected_samples = int(math.floor(len(self.dataset) // 256 * 256 / self.num_replicas))\n",
        "        self.shuffle = shuffle\n",
        "\n",
        "    def __iter__(self):\n",
        "        # deterministically shuffle based on epoch\n",
        "        g = tf.random.Generator.from_seed(seed=self.epoch)\n",
        "        \n",
        "        if self.shuffle:\n",
        "            indices = tf.random.shuffle(tf.range(len(self.dataset)), seed=g).numpy().tolist()\n",
        "        else:\n",
        "            indices = list(range(len(self.dataset)))\n",
        "\n",
        "        # add extra samples to make it evenly divisible\n",
        "        indices = [ele for ele in indices for i in range(3)]\n",
        "        indices += indices[:(self.total_size - len(indices))]\n",
        "        assert len(indices) == self.total_size\n",
        "\n",
        "        # subsample\n",
        "        indices = indices[self.rank:self.total_size:self.num_replicas]\n",
        "        assert len(indices) == self.num_samples\n",
        "\n",
        "        return iter(indices[:self.num_selected_samples])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_selected_samples\n",
        "\n",
        "    def set_epoch(self, epoch):\n",
        "        self.epoch = epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTPLrQqe14KV"
      },
      "outputs": [],
      "source": [
        "import torch.utils.data\n",
        "import torch.distributed as dist\n",
        "import numpy as np\n",
        "\n",
        "from timm.data.transforms_factory import create_transform\n",
        "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "from timm.data.distributed_sampler import OrderedDistributedSampler\n",
        "from timm.data.random_erasing import RandomErasing\n",
        "from timm.data.mixup import FastCollateMixup\n",
        "from timm.data.loader import fast_collate, PrefetchLoader, MultiEpochsDataLoader\n",
        "\n",
        "#from .rasampler import RASampler\n",
        "\n",
        "\n",
        "# def is_dist_avail_and_initialized():\n",
        "#     if not dist.is_available():\n",
        "#         return False\n",
        "#     if not dist.is_initialized():\n",
        "#         return False\n",
        "#     return True\n",
        "\n",
        "\n",
        "# def get_world_size():\n",
        "#     if not is_dist_avail_and_initialized():\n",
        "#         return 1\n",
        "#     return dist.get_world_size()\n",
        "\n",
        "\n",
        "# def get_rank():\n",
        "#     if not is_dist_avail_and_initialized():\n",
        "#         return 0\n",
        "#     return dist.get_rank()\n",
        "\n",
        "\n",
        "def create_loader(\n",
        "        dataset,\n",
        "        input_size,\n",
        "        batch_size,\n",
        "        is_training=False,\n",
        "        use_prefetcher=True,\n",
        "        no_aug=False,\n",
        "        re_prob=0.,\n",
        "        re_mode='const',\n",
        "        re_count=1,\n",
        "        re_split=False,\n",
        "        scale=None,\n",
        "        ratio=None,\n",
        "        hflip=0.5,\n",
        "        vflip=0.,\n",
        "        color_jitter=0.4,\n",
        "        auto_augment=None,\n",
        "        num_aug_splits=0,\n",
        "        interpolation='bilinear',\n",
        "        mean=IMAGENET_DEFAULT_MEAN,\n",
        "        std=IMAGENET_DEFAULT_STD,\n",
        "        #num_workers=0,\n",
        "        distributed=False,\n",
        "        crop_pct=None,\n",
        "        collate_fn=None,\n",
        "        pin_memory=False,\n",
        "        fp16=False,\n",
        "        tf_preprocessing=False,\n",
        "        use_multi_epochs_loader=False,\n",
        "        repeated_aug=False\n",
        "):\n",
        "    re_num_splits = 0\n",
        "    if re_split:\n",
        "        # apply RE to second half of batch if no aug split otherwise line up with aug split\n",
        "        re_num_splits = num_aug_splits or 2\n",
        "    dataset.transform = create_transform(\n",
        "        input_size,\n",
        "        is_training=is_training,\n",
        "        use_prefetcher=use_prefetcher,\n",
        "        no_aug=no_aug,\n",
        "        scale=scale,\n",
        "        ratio=ratio,\n",
        "        hflip=hflip,\n",
        "        vflip=vflip,\n",
        "        color_jitter=color_jitter,\n",
        "        auto_augment=auto_augment,\n",
        "        interpolation=interpolation,\n",
        "        mean=mean,\n",
        "        std=std,\n",
        "        crop_pct=crop_pct,\n",
        "        tf_preprocessing=tf_preprocessing,\n",
        "        re_prob=re_prob,\n",
        "        re_mode=re_mode,\n",
        "        re_count=re_count,\n",
        "        re_num_splits=re_num_splits,\n",
        "        separate=num_aug_splits > 0,\n",
        "    )\n",
        "\n",
        "    \n",
        "    sampler = None\n",
        "    if distributed:\n",
        "        if is_training:\n",
        "            if repeated_aug:\n",
        "                  print('using repeated_aug')\n",
        "                  num_replicas = tf.distribute.get_strategy().num_replicas_in_sync\n",
        "                  global_rank = tf.distribute.get_strategy().get_replica_context().replica_id_in_sync_group\n",
        "                  sampler = tf.data.experimental.RandomAccessSampler(\n",
        "                      num_samples=len(dataset),\n",
        "                      seed=0,\n",
        "                      num_replicas=num_replicas,\n",
        "                      start_index=global_rank,\n",
        "                  )\n",
        "            else:\n",
        "                  sampler = tf.data.experimental.DistributedSampler(\n",
        "                      dataset,\n",
        "                      num_replicas=tf.distribute.get_strategy().num_replicas_in_sync,\n",
        "                      shuffle=True,\n",
        "                      seed=0,\n",
        "                      drop_remainder=True,\n",
        "                  )\n",
        "        else:\n",
        "              # This will add extra duplicate entries to result in equal num\n",
        "              # of samples per-process, will slightly alter validation results\n",
        "          sampler = tf.data.experimental.Distribute(\n",
        "                  num_replicas=tf.distribute.get_strategy().num_replicas_in_sync,\n",
        "                  total_num_examples=len(dataset),\n",
        "                  shuffle=False,\n",
        "              )\n",
        "    else:\n",
        "      if is_training and repeated_aug:\n",
        "          print('using repeated_aug')\n",
        "                  #num_tasks = get_world_size()\n",
        "                  #global_rank = get_rank()\n",
        "          sampler = RASampler(\n",
        "                          dataset,shuffle=True\n",
        "                      )\n",
        "\n",
        "    if collate_fn is None:\n",
        "        collate_fn = fast_collate if use_prefetcher else torch.utils.data.dataloader.default_collate\n",
        "\n",
        "    loader_class = torch.utils.data.DataLoader\n",
        "\n",
        "    if use_multi_epochs_loader:\n",
        "      loader_class = MultiEpochsDataLoader\n",
        "\n",
        "    loader = loader_class(\n",
        "              dataset,\n",
        "              batch_size=batch_size,\n",
        "              shuffle=sampler is None and is_training,\n",
        "              #num_workers=num_workers,\n",
        "              sampler=sampler,\n",
        "              collate_fn=collate_fn,\n",
        "              pin_memory=pin_memory,\n",
        "              drop_last=is_training,\n",
        "          )\n",
        "    if use_prefetcher:\n",
        "        prefetch_re_prob = re_prob if is_training and not no_aug else 0.\n",
        "        loader = PrefetchLoader(\n",
        "                  loader,\n",
        "                  mean=mean,\n",
        "                  std=std,\n",
        "                  fp16=fp16,\n",
        "                  re_prob=prefetch_re_prob,\n",
        "                  re_mode=re_mode,\n",
        "                  re_count=re_count,\n",
        "                  re_num_splits=re_num_splits\n",
        "              )\n",
        "\n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a1WOMLO2nr_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# relative position embedding\n",
        "# References: https://arxiv.org/abs/2009.13658\n",
        "# --------------------------------------------------------\n",
        "def get_2d_relative_pos_embed(embed_dim, grid_size):\n",
        "    \"\"\"\n",
        "    grid_size: int of the grid height and width\n",
        "    return:\n",
        "    pos_embed: [grid_size*grid_size, grid_size*grid_size]\n",
        "    \"\"\"\n",
        "    pos_embed = get_2d_sincos_pos_embed(embed_dim, grid_size)\n",
        "    relative_pos = 2 * np.matmul(pos_embed, pos_embed.transpose()) / pos_embed.shape[1]\n",
        "    return relative_pos\n",
        "\n",
        "\n",
        "# --------------------------------------------------------\n",
        "# 2D sine-cosine position embedding\n",
        "# References:\n",
        "# Transformer: https://github.com/tensorflow/models/blob/master/official/nlp/transformer/model_utils.py\n",
        "# MoCo v3: https://github.com/facebookresearch/moco-v3\n",
        "# --------------------------------------------------------\n",
        "def get_2d_sincos_pos_embed(embed_dim, grid_size, cls_token=False):\n",
        "    \"\"\"\n",
        "    grid_size: int of the grid height and width\n",
        "    return:\n",
        "    pos_embed: [grid_size*grid_size, embed_dim] or [1+grid_size*grid_size, embed_dim] (w/ or w/o cls_token)\n",
        "    \"\"\"\n",
        "    grid_h = np.arange(grid_size, dtype=np.float32)\n",
        "    grid_w = np.arange(grid_size, dtype=np.float32)\n",
        "    grid = np.meshgrid(grid_w, grid_h)  # here w goes first\n",
        "    grid = np.stack(grid, axis=0)\n",
        "\n",
        "    grid = grid.reshape([2, 1, grid_size, grid_size])\n",
        "    pos_embed = get_2d_sincos_pos_embed_from_grid(embed_dim, grid)\n",
        "    if cls_token:\n",
        "        pos_embed = np.concatenate([np.zeros([1, embed_dim]), pos_embed], axis=0)\n",
        "    return pos_embed\n",
        "\n",
        "\n",
        "def get_2d_sincos_pos_embed_from_grid(embed_dim, grid):\n",
        "    assert embed_dim % 2 == 0\n",
        "\n",
        "    # use half of dimensions to encode grid_h\n",
        "    emb_h = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[0])  # (H*W, D/2)\n",
        "    emb_w = get_1d_sincos_pos_embed_from_grid(embed_dim // 2, grid[1])  # (H*W, D/2)\n",
        "\n",
        "    emb = np.concatenate([emb_h, emb_w], axis=1) # (H*W, D)\n",
        "    return emb\n",
        "\n",
        "\n",
        "def get_1d_sincos_pos_embed_from_grid(embed_dim, pos):\n",
        "    \"\"\"\n",
        "    embed_dim: output dimension for each position\n",
        "    pos: a list of positions to be encoded: size (M,)\n",
        "    out: (M, D)\n",
        "    \"\"\"\n",
        "    assert embed_dim % 2 == 0\n",
        "    omega = np.arange(embed_dim // 2, dtype=np.float)\n",
        "    omega /= embed_dim / 2.\n",
        "    omega = 1. / 10000**omega  # (D/2,)\n",
        "\n",
        "    pos = pos.reshape(-1)  # (M,)\n",
        "    out = np.einsum('m,d->md', pos, omega)  # (M, D/2), outer product\n",
        "\n",
        "    emb_sin = np.sin(out) # (M, D/2)\n",
        "    emb_cos = np.cos(out) # (M, D/2)\n",
        "\n",
        "    emb = np.concatenate([emb_sin, emb_cos], axis=1)  # (M, D)\n",
        "    return emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYtdNWSH2z7X"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def pairwise_distance(x):\n",
        "    \"\"\"\n",
        "    Compute pairwise distance of a point cloud.\n",
        "    Args:\n",
        "        x: tensor (batch_size, num_points, num_dims)\n",
        "    Returns:\n",
        "        pairwise distance: (batch_size, num_points, num_points)\n",
        "    \"\"\"\n",
        "    x_inner = -2*torch.matmul(x, x.transpose(2, 1))\n",
        "    x_square = tf.reduce_sum(tf.multiply(x, x), axis=-1, keepdims=True)\n",
        "    return x_square + x_inner + x_square.transpose(2, 1)\n",
        "    \n",
        "\n",
        "def part_pairwise_distance(x, start_idx=0, end_idx=1):\n",
        "    \"\"\"\n",
        "    Compute pairwise distance of a point cloud.\n",
        "    Args:\n",
        "        x: tensor (batch_size, num_points, num_dims)\n",
        "    Returns:\n",
        "        pairwise distance: (batch_size, num_points, num_points)\n",
        "    \"\"\"\n",
        "    x_part = x[:, start_idx:end_idx]\n",
        "    x_square_part = tf.reduce_sum(tf.multiply(x_part, x_part), axis=-1, keepdims=True)\n",
        "    x_inner = -2 * tf.matmul(x_part, tf.transpose(x, perm=[0, 2, 1]))\n",
        "    x_square = tf.reduce_sum(tf.multiply(x, x), axis=-1, keepdims=True)\n",
        "    return x_square_part + x_inner + x_square.transpose(2, 1)\n",
        "\n",
        "\n",
        "def xy_pairwise_distance(x, y):\n",
        "    \"\"\"\n",
        "    Compute pairwise distance of a point cloud.\n",
        "    Args:\n",
        "        x: tensor (batch_size, num_points, num_dims)\n",
        "    Returns:\n",
        "        pairwise distance: (batch_size, num_points, num_points)\n",
        "    \"\"\"\n",
        "    xy_inner = -2 * tf.matmul(x, tf.transpose(y, perm=[0, 2, 1]))\n",
        "    x_square = tf.reduce_sum(tf.multiply(x, x), axis=-1, keepdims=True)\n",
        "    y_square = tf.reduce_sum(tf.multiply(y, y), axis=-1, keepdims=True)\n",
        "    return x_square + xy_inner + y_square.transpose(2, 1)\n",
        "\n",
        "\n",
        "def dense_knn_matrix(x, k=16, relative_pos=None):\n",
        "    \"\"\"Get KNN based on the pairwise distance.\n",
        "    Args:\n",
        "        x: (batch_size, num_dims, num_points, 1)\n",
        "        k: int\n",
        "    Returns:\n",
        "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
        "    \"\"\"\n",
        "    x = x.transpose(2, 1).squeeze(-1)\n",
        "    batch_size, n_points, n_dims = x.shape\n",
        "        ### memory efficient implementation ###\n",
        "    n_part = 10000\n",
        "    if n_points > n_part:\n",
        "      nn_idx_list = []\n",
        "      groups = math.ceil(n_points / n_part)\n",
        "      for i in range(groups):\n",
        "        start_idx = n_part * i\n",
        "        end_idx = min(n_points, n_part * (i + 1))\n",
        "        dist = part_pairwise_distance(x.detach(), start_idx, end_idx)\n",
        "        if relative_pos is not None:\n",
        "          dist += relative_pos[:, start_idx:end_idx]\n",
        "        dist_neg = tf.negative(dist)\n",
        "        _, nn_idx_part = tf.math.top_k(dist_neg, k=k)\n",
        "        nn_idx_list += [nn_idx_part]\n",
        "        nn_idx = tf.concat(nn_idx_list, axis=1)\n",
        "\n",
        "    else:\n",
        "      dist = pairwise_distance(x.detach())\n",
        "      if relative_pos is not None:\n",
        "        dist += relative_pos\n",
        "      dist_neg = tf.negative(dist)\n",
        "      _, nn_idx_part = tf.math.top_k(dist_neg, k=k)# b, n, k\n",
        "        ######\n",
        "      n_points_tensor = tf.cast(n_points, dtype=tf.int32)\n",
        "      batch_indices = tf.reshape(tf.range(batch_size), [-1, 1, 1])\n",
        "      point_indices = tf.reshape(tf.range(n_points_tensor), [1, -1, 1])\n",
        "      point_indices = tf.tile(point_indices, [batch_size, 1, k])\n",
        "      center_indices = tf.transpose(point_indices, perm=[0, 2, 1])\n",
        "      nn_center_indices = tf.stack([nn_idx, center_indices], axis=0)\n",
        "    return nn_center_indices\n",
        "\n",
        "\n",
        "def xy_dense_knn_matrix(x, y, k=16, relative_pos=None):\n",
        "    \"\"\"Get KNN based on the pairwise distance.\n",
        "    Args:\n",
        "        x: (batch_size, num_dims, num_points, 1)\n",
        "        k: int\n",
        "    Returns:\n",
        "        nearest neighbors: (batch_size, num_points, k) (batch_size, num_points, k)\n",
        "    \"\"\"\n",
        "    x = x.transpose(2, 1).squeeze(-1)\n",
        "    y = y.transpose(2, 1).squeeze(-1)\n",
        "    batch_size, n_points, n_dims = x.shape\n",
        "    dist = xy_pairwise_distance(x.detach(), y.detach())\n",
        "    if relative_pos is not None:\n",
        "      dist += relative_pos\n",
        "    dist_neg = tf.negative(dist)\n",
        "    _, nn_idx_part = tf.math.top_k(dist_neg, k=k)\n",
        "    n_points_tensor = tf.cast(n_points, dtype=tf.int32)\n",
        "    batch_indices = tf.reshape(tf.range(batch_size), [-1, 1, 1])\n",
        "    point_indices = tf.reshape(tf.range(n_points_tensor), [1, -1, 1])\n",
        "    point_indices = tf.tile(point_indices, [batch_size, 1, k])\n",
        "    center_indices = tf.transpose(point_indices, perm=[0, 2, 1])\n",
        "    nn_center_indices = tf.stack([nn_idx_part, center_indices], axis=0)\n",
        "    return nn_center_indices\n",
        "\n",
        "\n",
        "class DenseDilated(nn.Module):\n",
        "    \"\"\"\n",
        "    Find dilated neighbor from neighbor list\n",
        "    edge_index: (2, batch_size, num_points, k)\n",
        "    \"\"\"\n",
        "    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n",
        "        super(DenseDilated, self).__init__()\n",
        "        self.dilation = dilation\n",
        "        self.stochastic = stochastic\n",
        "        self.epsilon = epsilon\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, edge_index):\n",
        "        if self.stochastic:\n",
        "           if tf.random.uniform(shape=[1]) < self.epsilon and self.training:\n",
        "\n",
        "                num = self.k * self.dilation\n",
        "                randnum = tf.random.shuffle(tf.range(num))[:self.k]\n",
        "\n",
        "                edge_index = edge_index[:, :, :, randnum]\n",
        "           else:\n",
        "                edge_index = edge_index[:, :, :, ::self.dilation]\n",
        "        else:\n",
        "            edge_index = edge_index[:, :, :, ::self.dilation]\n",
        "        return edge_index\n",
        "\n",
        "\n",
        "class DenseDilatedKnnGraph(nn.Module):\n",
        "    \"\"\"\n",
        "    Find the neighbors' indices based on dilated knn\n",
        "    \"\"\"\n",
        "    def __init__(self, k=9, dilation=1, stochastic=False, epsilon=0.0):\n",
        "        super(DenseDilatedKnnGraph, self).__init__()\n",
        "        self.dilation = dilation\n",
        "        self.stochastic = stochastic\n",
        "        self.epsilon = epsilon\n",
        "        self.k = k\n",
        "        self._dilated = DenseDilated(k, dilation, stochastic, epsilon)\n",
        "\n",
        "    def forward(self, x, y=None, relative_pos=None):\n",
        "        if y is not None:\n",
        "            #### normalize\n",
        "            norm = tf.norm(x, ord=2.0, axis=1, keepdims=True)\n",
        "            x = x / norm\n",
        "            norm = tf.norm(y, ord=2.0, axis=1, keepdims=True)\n",
        "            y = y / norm\n",
        "           \n",
        "            ####\n",
        "            edge_index = xy_dense_knn_matrix(x, y, self.k * self.dilation, relative_pos)\n",
        "        else:\n",
        "            #### normalize\n",
        "            norm = tf.norm(x, ord=2.0, axis=1, keepdims=True)\n",
        "            x = x / norm\n",
        "            ####\n",
        "            edge_index = dense_knn_matrix(x, self.k * self.dilation, relative_pos)\n",
        "        return self._dilated(edge_index)\n",
        "        x_square = tf.reduce_sum(tf.square(x), axis=-1, keepdims=True)\n",
        "        return x_square + x_inner + x_square.transpose(2, 1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssssAZj320Eq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Sequential as Seq, Linear as Lin, Conv2d\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential as Seq\n",
        "from tensorflow.keras.layers import Dense as Lin\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "\n",
        "##############################\n",
        "#    Basic layers\n",
        "##############################\n",
        "\n",
        "def hardswish(x):\n",
        "    return x * tf.nn.relu6(x + 3) / 6\n",
        "\n",
        "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
        "    # activation layer\n",
        "\n",
        "    act = act.lower()\n",
        "    if act == 'relu':\n",
        "        layer = tf.nn.relu\n",
        "    elif act == 'leakyrelu':\n",
        "        layer = tf.keras.layers.LeakyReLU(alpha=0.1)\n",
        "    elif act == 'prelu':\n",
        "        layer = tf.keras.layers.PReLU(alpha_initializer=tf.keras.initializers.Constant(value=-0.25)),\n",
        "    elif act == 'gelu':\n",
        "        layer = tf.keras.activations.gelu\n",
        "    else:\n",
        "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
        "    return layer\n",
        "\n",
        "\n",
        "def norm_layer(norm, nc):\n",
        "    # normalization layer 2d\n",
        "    norm = norm.lower()\n",
        "    if norm == 'batch':\n",
        "        layer = nn.BatchNorm2d(nc, affine=True)\n",
        "    elif norm == 'instance':\n",
        "        layer = nn.InstanceNorm2d(nc, affine=False)\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [%s] is not found' % norm)\n",
        "    return layer\n",
        "\n",
        "\n",
        "class MLP(Seq):\n",
        "    def __init__(self, channels, act='relu', norm=None, bias=True):\n",
        "        m = []\n",
        "        for i in range(1, len(channels)):\n",
        "            m.append(Dense(channels[i], input_shape=(channels[i-1],), use_bias=True))\n",
        "            if act is not None and act.lower() != 'none':\n",
        "                m.append(act_layer(act))\n",
        "            if norm is not None and norm.lower() != 'none':\n",
        "                m.append(norm_layer(norm, channels[-1]))\n",
        "        super(MLP, self).__init__(*m)\n",
        "\n",
        "\n",
        "class BasicConv(Seq):\n",
        "    def __init__(self, channels, act='relu', norm=None, bias=True, drop=0.):\n",
        "        m = []\n",
        "        for i in range(1, len(channels)):\n",
        "            m.append(Conv2D(filters=channels[i], kernel_size=1, strides=1, padding='valid', use_bias=bias, groups=4, input_shape=(None, None, channels[i-1])))\n",
        "            if norm is not None and norm.lower() != 'none':\n",
        "                m.append(norm_layer(norm, channels[-1]))\n",
        "            if act is not None and act.lower() != 'none':\n",
        "                m.append(act_layer(act))\n",
        "            if drop > 0:\n",
        "                m.append(tf.keras.layers.Dropout(drop))\n",
        "\n",
        "        super(BasicConv, self).__init__(*m)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, Conv2D):\n",
        "                tf.keras.initializers.he_normsal(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    tf.zeros_initializer(m.bias)\n",
        "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.InstanceNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "def batched_index_select(x, idx):\n",
        "    r\"\"\"fetches neighbors features from a given neighbor idx\n",
        "    Args:\n",
        "        x (Tensor): input feature Tensor\n",
        "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times 1}`.\n",
        "        idx (Tensor): edge_idx\n",
        "                :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times N \\times l}`.\n",
        "    Returns:\n",
        "        Tensor: output neighbors features\n",
        "            :math:`\\mathbf{X} \\in \\mathbb{R}^{B \\times C \\times N \\times k}`.\n",
        "    \"\"\"\n",
        "    batch_size, num_dims, num_vertices_reduced = x.shape[:3]\n",
        "    _, num_vertices, k = idx.shape\n",
        "    idx_base = tf.range(0, batch_size, dtype=tf.int32)[:, tf.newaxis, tf.newaxis] * num_vertices_reduced\n",
        "    idx = idx + idx_base\n",
        "    idx = idx.contiguous().view(-1)\n",
        "\n",
        "    x = x.transpose(2, 1)\n",
        "    feature = x.contiguous().view(batch_size * num_vertices_reduced, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_vertices, k, num_dims).permute(0, 3, 1, 2).contiguous()\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0eT8mfet20Hc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "# from .torch_nn import BasicConv, batched_index_select, act_layer\n",
        "# from .torch_edge import DenseDilatedKnnGraph\n",
        "# from .pos_embed import get_2d_relative_pos_embed\n",
        "import torch.nn.functional as F\n",
        "from timm.models.layers import DropPath\n",
        "\n",
        "\n",
        "class MRConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Max-Relative Graph Convolution (Paper: https://arxiv.org/abs/1904.03751) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(MRConv2d, self).__init__()\n",
        "        self.nn = BasicConv([in_channels*2, out_channels], act, norm, bias)\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        x_i = batched_index_select(x, edge_index[1])\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        x_j = tf.reduce_max(x_j - x_i, axis=-1, keepdims=True)\n",
        "        b, c, n, _ = x.shape\n",
        "        x = tf.concat([tf.expand_dims(x, axis=2), tf.expand_dims(x_j, axis=2)], axis=2)\n",
        "        x = tf.reshape(x, [b, 2*c, n, -1])\n",
        "        return self.nn(x)\n",
        "\n",
        "\n",
        "class EdgeConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Edge convolution layer (with activation, batch normalization) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(EdgeConv2d, self).__init__()\n",
        "        self.nn = BasicConv([in_channels * 2, out_channels], act, norm, bias)\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        x_i = batched_index_select(x, edge_index[1])\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        concatenated_tensor = tf.concat([x_i, x_j - x_i], axis=1)\n",
        "        nn_output = self.nn(concatenated_tensor)\n",
        "        max_value = tf.reduce_max(nn_output, axis=-1, keepdims=True)\n",
        "        return max_value\n",
        "\n",
        "\n",
        "class GraphSAGE(nn.Module):\n",
        "    \"\"\"\n",
        "    GraphSAGE Graph Convolution (Paper: https://arxiv.org/abs/1706.02216) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.nn1 = BasicConv([in_channels, in_channels], act, norm, bias)\n",
        "        self.nn2 = BasicConv([in_channels*2, out_channels], act, norm, bias)\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        nn1_output = self.nn1(x_j)\n",
        "        x_j, _ = tf.reduce_max(nn1_output, axis=-1, keepdims=True)\n",
        "        concatenated_tensor = tf.concat([x, x_j], axis=1)\n",
        "        nn2_output = self.nn2(concatenated_tensor)\n",
        "        return nn2_output\n",
        "\n",
        "\n",
        "class GINConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    GIN Graph Convolution (Paper: https://arxiv.org/abs/1810.00826) for dense data type\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, act='relu', norm=None, bias=True):\n",
        "        super(GINConv2d, self).__init__()\n",
        "        self.nn = BasicConv([in_channels, out_channels], act, norm, bias)\n",
        "        eps_init = 0.0\n",
        "        eps_init = tf.constant_initializer([eps_init])\n",
        "        eps_param = tf.Variable(name='eps_param', shape=[1], initializer=eps_init, dtype=tf.float32)\n",
        "        self.eps = eps_param\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        if y is not None:\n",
        "            x_j = batched_index_select(y, edge_index[0])\n",
        "        else:\n",
        "            x_j = batched_index_select(x, edge_index[0])\n",
        "        x_j = torch.sum(x_j, -1, keepdim=True)\n",
        "        return self.nn((1 + self.eps) * x + x_j)\n",
        "\n",
        "\n",
        "class GraphConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Static graph convolution layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, conv='edge', act='relu', norm=None, bias=True):\n",
        "        super(GraphConv2d, self).__init__()\n",
        "        if conv == 'edge':\n",
        "            self.gconv = EdgeConv2d(in_channels, out_channels, act, norm, bias)\n",
        "        elif conv == 'mr':\n",
        "            self.gconv = MRConv2d(in_channels, out_channels, act, norm, bias)\n",
        "        elif conv == 'sage':\n",
        "            self.gconv = GraphSAGE(in_channels, out_channels, act, norm, bias)\n",
        "        elif conv == 'gin':\n",
        "            self.gconv = GINConv2d(in_channels, out_channels, act, norm, bias)\n",
        "        else:\n",
        "            raise NotImplementedError('conv:{} is not supported'.format(conv))\n",
        "\n",
        "    def forward(self, x, edge_index, y=None):\n",
        "        return self.gconv(x, edge_index, y)\n",
        "\n",
        "\n",
        "class DyGraphConv2d(GraphConv2d):\n",
        "    \"\"\"\n",
        "    Dynamic graph convolution layer\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=9, dilation=1, conv='edge', act='relu',\n",
        "                 norm=None, bias=True, stochastic=False, epsilon=0.0, r=1):\n",
        "        super(DyGraphConv2d, self).__init__(in_channels, out_channels, conv, act, norm, bias)\n",
        "        self.k = kernel_size\n",
        "        self.d = dilation\n",
        "        self.r = r\n",
        "        self.dilated_knn_graph = DenseDilatedKnnGraph(kernel_size, dilation, stochastic, epsilon)\n",
        "\n",
        "    def forward(self, x, relative_pos=None):\n",
        "        B, C, H, W = x.shape\n",
        "        y = None\n",
        "        if self.r > 1:\n",
        "            y = F.avg_pool2d(x, self.r, self.r)\n",
        "            y = y.reshape(B, C, -1, 1).contiguous()            \n",
        "        x = x.reshape(B, C, -1, 1).contiguous()\n",
        "        edge_index = self.dilated_knn_graph(x, y, relative_pos)\n",
        "        x = super(DyGraphConv2d, self).forward(x, edge_index, y)\n",
        "        return x.reshape(B, -1, H, W).contiguous()\n",
        "\n",
        "\n",
        "class Grapher(nn.Module):\n",
        "    \"\"\"\n",
        "    Grapher module with graph convolution and fc layers\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, kernel_size=9, dilation=1, conv='edge', act='relu', norm=None,\n",
        "                 bias=True,  stochastic=False, epsilon=0.0, r=1, n=196, drop_path=0.0, relative_pos=False):\n",
        "        super(Grapher, self).__init__()\n",
        "        self.channels = in_channels\n",
        "        self.n = n\n",
        "        self.r = r\n",
        "        self.fc1 = tf.keras.Sequential([\n",
        "                   tf.keras.layers.Conv2D(in_channels, kernel_size=1, strides=1, padding='valid'),\n",
        "                  tf.keras.layers.BatchNormalization()\n",
        "                     ])\n",
        "        self.graph_conv = DyGraphConv2d(in_channels, in_channels * 2, kernel_size, dilation, conv,\n",
        "                              act, norm, bias, stochastic, epsilon, r)\n",
        "        self.fc2 = tf.keras.Sequential([\n",
        "                   tf.keras.layers.Conv2D(in_channels, kernel_size=1, strides=1, padding='valid'),\n",
        "                   tf.keras.layers.BatchNormalization()\n",
        "                     ])\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else tf.identity()\n",
        "        self.relative_pos = None\n",
        "        if relative_pos:\n",
        "            print('using relative_pos')\n",
        "            relative_pos_tensor = tf.convert_to_tensor(np.float32(get_2d_relative_pos_embed(in_channels, int(n**0.5))), dtype=tf.float32)\n",
        "            relative_pos_tensor = tf.expand_dims(tf.expand_dims(relative_pos_tensor, axis=0), axis=1)\n",
        "            relative_pos_tensor = tf.image.resize(relative_pos_tensor, size=(n, n//(r*r)), method=tf.image.ResizeMethod.BICUBIC, \n",
        "                                           preserve_aspect_ratio=False, antialias=False)\n",
        "            self.relative_pos = tf.Variable(-tf.squeeze(relative_pos_tensor, axis=1), trainable=False)\n",
        "\n",
        "    def _get_relative_pos(self, relative_pos, H, W):\n",
        "        if relative_pos is None or H * W == self.n:\n",
        "            return relative_pos\n",
        "        else:\n",
        "            N = H * W\n",
        "            N_reduced = N // (self.r * self.r)\n",
        "            relative_pos = tf.expand_dims(relative_pos, axis=0)\n",
        "            relative_pos = tf.image.resize(relative_pos, size=(N, N_reduced), method=tf.image.ResizeMethod.BICUBIC, \n",
        "                                           preserve_aspect_ratio=False, antialias=False)\n",
        "            relative_pos = tf.squeeze(relative_pos, axis=0)\n",
        "            return relative_pos\n",
        "\n",
        "    def forward(self, x):\n",
        "        _tmp = x\n",
        "        x = self.fc1(x)\n",
        "        B, C, H, W = x.shape\n",
        "        relative_pos = self._get_relative_pos(self.relative_pos, H, W)\n",
        "        x = self.graph_conv(x, relative_pos)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop_path(x) + _tmp\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJHA2o_820LS"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "#from torch.nn import Sequential as Seq\n",
        "from tensorflow.keras import Sequential as Seq\n",
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "from timm.models.helpers import load_pretrained\n",
        "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
        "from timm.models.registry import register_model\n",
        "\n",
        "#from gcn_lib import Grapher, act_layer\n",
        "\n",
        "\n",
        "def _cfg(url='', **kwargs):\n",
        "    return {\n",
        "        'url': url,\n",
        "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n",
        "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
        "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n",
        "        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "\n",
        "default_cfgs = {\n",
        "    'vig_224_gelu': _cfg(\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "    'vig_b_224_gelu': _cfg(\n",
        "        crop_pct=0.95, mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "class FFN(tf.keras.layers.Layer):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act='relu', drop_path=0.0):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = model = tf.keras.Sequential([\n",
        "                       tf.keras.layers.Conv2D(hidden_features, 1, strides=1, padding='valid', input_shape=(None, None, in_features)),\n",
        "                       tf.keras.layers.BatchNormalization()])\n",
        "        self.act = act_layer(act)\n",
        "        self.fc2 = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Conv2D(out_features, 1, strides=1, padding='valid', input_shape=(None, None, hidden_features)),\n",
        "                  tf.keras.layers.BatchNormalization()\n",
        "                  ])\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else tf.identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop_path(x) + shortcut\n",
        "        return x#.reshape(B, C, N, 1)\n",
        "\n",
        "\n",
        "class Stem(tf.keras.layers.Layer):\n",
        "    \"\"\" Image to Visual Embedding\n",
        "    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n",
        "        super().__init__()        \n",
        "        self.convs = tf.keras.Sequential([\n",
        "                     tf.keras.layers.Conv2D(out_dim // 2, 3, strides=2, padding='same', input_shape=(None, None, in_dim)),\n",
        "                     tf.keras.layers.BatchNormalization(),\n",
        "                     tf.keras.layers.Activation(act),\n",
        "                     tf.keras.layers.Conv2D(out_dim, 3, strides=2, padding='same'),\n",
        "                     tf.keras.layers.BatchNormalization(),\n",
        "                     tf.keras.layers.Activation(act),\n",
        "                     tf.keras.layers.Conv2D(out_dim, 3, strides=1, padding='same'),\n",
        "                     tf.keras.layers.BatchNormalization()\n",
        "                     ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Downsample(tf.keras.layers.Layer):\n",
        "    \"\"\" Convolution-based downsample\n",
        "    \"\"\"\n",
        "    def __init__(self, in_dim=3, out_dim=768):\n",
        "        super().__init__()        \n",
        "        self.conv = tf.keras.Sequential([\n",
        "                    tf.keras.layers.Conv2D(out_dim, 3, strides=2, padding='same', input_shape=(None, None, in_dim)),\n",
        "                    tf.keras.layers.BatchNormalization()\n",
        "                    ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DeepGCN(tf.keras.layers.Layer):\n",
        "    def __init__(self, opt):\n",
        "        super(DeepGCN, self).__init__()\n",
        "        print(opt)\n",
        "        k = opt.k\n",
        "        act = opt.act\n",
        "        norm = opt.norm\n",
        "        bias = opt.bias\n",
        "        epsilon = opt.epsilon\n",
        "        stochastic = opt.use_stochastic\n",
        "        conv = opt.conv\n",
        "        emb_dims = opt.emb_dims\n",
        "        drop_path = opt.drop_path\n",
        "        \n",
        "        blocks = opt.blocks\n",
        "        self.n_blocks = sum(blocks)\n",
        "        channels = opt.channels\n",
        "        reduce_ratios = [4, 2, 1, 1]\n",
        "        dpr = [x.item() for x in tf.linspace(0.0, drop_path, self.n_blocks)]  # stochastic depth decay rule \n",
        "        num_knn = [int(x.item()) for x in tf.fill([self.n_blocks], k)]  # number of knn's k\n",
        "        max_dilation = 49 // max(num_knn)\n",
        "        \n",
        "        self.stem = Stem(out_dim=channels[0], act=act)\n",
        "        self.pos_embed = tf.Variable(tf.zeros([1, channels[0], 224//4, 224//4]), trainable=True)\n",
        "        HW = 224 // 4 * 224 // 4\n",
        "        \n",
        "        self.backbone = []\n",
        "        idx = 0\n",
        "        for i in range(len(blocks)):\n",
        "            if i > 0:\n",
        "                self.backbone.append(Downsample(channels[i-1], channels[i]))\n",
        "                HW = HW // 4\n",
        "            for j in range(blocks[i]):\n",
        "                self.backbone += [\n",
        "                    Seq(Grapher(channels[i], num_knn[idx], min(idx // 4 + 1, max_dilation), conv, act, norm,\n",
        "                                    bias, stochastic, epsilon, reduce_ratios[i], n=HW, drop_path=dpr[idx],\n",
        "                                    relative_pos=True),\n",
        "                          FFN(channels[i], channels[i] * 4, act=act, drop_path=dpr[idx])\n",
        "                         )]\n",
        "                idx += 1\n",
        "        self.backbone = Seq(*self.backbone)\n",
        "\n",
        "        self.prediction = tf.keras.Sequential([\n",
        "                    tf.keras.layers.Conv2D(1024, 1, use_bias=True),\n",
        "                    tf.keras.layers.BatchNormalization(),\n",
        "                    tf.keras.layers.Activation(act_layer(act)),\n",
        "                    tf.keras.layers.Dropout(opt.dropout),\n",
        "                    tf.keras.layers.Conv2D(opt.n_classes, 1, use_bias=True)\n",
        "                  ])\n",
        "        self.model_init()\n",
        "\n",
        "    def model_init(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, tf.keras.layers.Conv2D):\n",
        "                tf.keras.initializers.VarianceScaling(scale=2.0, mode='fan_in', distribution='truncated_normal')(m.weights[0])\n",
        "                # Set the weights to be trainable\n",
        "                m.weights[0].trainable = True\n",
        "                if m.bias is not None:\n",
        "                   m.bias.assign(tf.zeros_like(m.bias))\n",
        "                   m.bias.trainable = True\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.stem(inputs) + self.pos_embed\n",
        "        B, C, H, W = x.shape\n",
        "        for i in range(len(self.backbone)):\n",
        "            x = self.backbone[i](x)\n",
        "\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.squeeze(x, axis=[1, 2])\n",
        "        return tf.squeeze(self.prediction(x))\n",
        "\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvig_ti_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
        "            self.k = 9 # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.dropout = 0.0 # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n",
        "            self.channels = [48, 96, 240, 384] # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.emb_dims = 1024 # Dimension of embeddings\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvig_s_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
        "            self.k = 9 # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.dropout = 0.0 # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "            self.blocks = [2,2,6,2] # number of basic blocks in the backbone\n",
        "            self.channels = [80, 160, 400, 640] # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.emb_dims = 1024 # Dimension of embeddings\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvig_m_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
        "            self.k = 9 # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.dropout = 0.0 # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "            self.blocks = [2,2,16,2] # number of basic blocks in the backbone\n",
        "            self.channels = [96, 192, 384, 768] # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.emb_dims = 1024 # Dimension of embeddings\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['vig_224_gelu']\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def pvig_b_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=1000, drop_path_rate=0.0, **kwargs):\n",
        "            self.k = 9 # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.dropout = 0.0 # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "            self.blocks = [2,2,18,2] # number of basic blocks in the backbone\n",
        "            self.channels = [128, 256, 512, 1024] # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.emb_dims = 1024 # Dimension of embeddings\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['vig_b_224_gelu']\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRf6Hb892fIF"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential as Seq\n",
        "#from gcn_lib import Grapher, act_layer\n",
        "\n",
        "from timm.data import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
        "from timm.models.helpers import load_pretrained\n",
        "from timm.models.layers import DropPath, to_2tuple, trunc_normal_\n",
        "from timm.models.registry import register_model\n",
        "\n",
        "\n",
        "def _cfg(url='', **kwargs):\n",
        "    return {\n",
        "        'url': url,\n",
        "        'num_classes': 1000, 'input_size': (3, 224, 224), 'pool_size': None,\n",
        "        'crop_pct': .9, 'interpolation': 'bicubic',\n",
        "        'mean': IMAGENET_DEFAULT_MEAN, 'std': IMAGENET_DEFAULT_STD,\n",
        "        'first_conv': 'patch_embed.proj', 'classifier': 'head',\n",
        "        **kwargs\n",
        "    }\n",
        "\n",
        "\n",
        "default_cfgs = {\n",
        "    'gnn_patch16_224': _cfg(\n",
        "        crop_pct=0.9, input_size=(3, 224, 224),\n",
        "        mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5),\n",
        "    ),\n",
        "}\n",
        "\n",
        "\n",
        "class FFN(tf.keras.layers.Layer):\n",
        "    def __init__(self, in_features, hidden_features=None, out_features=None, act='relu', drop_path=0.0):\n",
        "        super().__init__()\n",
        "        out_features = out_features or in_features\n",
        "        hidden_features = hidden_features or in_features\n",
        "        self.fc1 = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(hidden_features, kernel_size=1, strides=1, padding='valid'),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "        ])\n",
        "        self.act = act_layer(act)\n",
        "        self.fc2 = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(out_features, kernel_size=1, strides=1, padding='valid'),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "        ])\n",
        "        self.drop_path = DropPath(drop_path) if drop_path > 0. else tf.keras.layers.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        shortcut = x\n",
        "        x = self.fc1(x)\n",
        "        x = self.act(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.drop_path(x, training=training, drop_prob=drop_prob) + shortcut\n",
        "        return x\n",
        "\n",
        "\n",
        "class Stem(tf.keras.layers.Layer):\n",
        "    \"\"\" Image to Visual Word Embedding\n",
        "    Overlap: https://arxiv.org/pdf/2106.13797.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, img_size=224, in_dim=3, out_dim=768, act='relu'):\n",
        "        super().__init__()\n",
        "        self.convs = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(out_dim//8, kernel_size=3, strides=2, padding='same'),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            act_layer(act),\n",
        "            tf.keras.layers.Conv2D(out_dim//4, kernel_size=3, strides=2, padding='same'),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            act_layer(act),\n",
        "            tf.keras.layers.Conv2D(out_dim//2, kernel_size=3, strides=2, padding='same'),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            act_layer(act),\n",
        "            tf.keras.layers.Conv2D(out_dim, kernel_size=3, strides=2, padding='same'),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            act_layer(act),\n",
        "            tf.keras.layers.Conv2D(out_dim, kernel_size=3, strides=1, padding='same'),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convs(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class DeepGCN(torch.nn.Module):\n",
        "    def __init__(self, opt):\n",
        "        super(DeepGCN, self).__init__()\n",
        "        channels = opt.n_filters\n",
        "        k = opt.k\n",
        "        act = opt.act\n",
        "        norm = opt.norm\n",
        "        bias = opt.bias\n",
        "        epsilon = opt.epsilon\n",
        "        stochastic = opt.use_stochastic\n",
        "        conv = opt.conv\n",
        "        self.n_blocks = opt.n_blocks\n",
        "        drop_path = opt.drop_path\n",
        "        \n",
        "        self.stem = Stem(out_dim=channels, act=act)\n",
        "\n",
        "        dpr = [x.item() for x in tf.linspace(0, drop_path, self.n_blocks)]  # stochastic depth decay rule \n",
        "        print('dpr', dpr)\n",
        "        num_knn = [int(x.item()) for x in tf.linspace(k, 2*k, self.n_blocks)]  # number of knn's k\n",
        "        print('num_knn', num_knn)\n",
        "        max_dilation = 196 // max(num_knn)\n",
        "        \n",
        "        self.pos_embed = tf.Variable(tf.zeros([1, channels, 14, 14]), trainable=True)\n",
        "\n",
        "        if opt.use_dilation:\n",
        "            self.backbone = tf.keras.Sequential([tf.keras.Sequential([\n",
        "                Grapher(channels, num_knn[i], min(i // 4 + 1, max_dilation), conv, act, norm,\n",
        "                        bias, stochastic, epsilon, 1, drop_path=dpr[i]),\n",
        "                FFN(channels, channels * 4, act=act, drop_path=dpr[i])\n",
        "            ]) for i in range(self.n_blocks)])\n",
        "        else:\n",
        "            self.backbone = tf.keras.Sequential([tf.keras.Sequential([\n",
        "                Grapher(channels, num_knn[i], 1, conv, act, norm,\n",
        "                        bias, stochastic, epsilon, 1, drop_path=dpr[i]),\n",
        "                FFN(channels, channels * 4, act=act, drop_path=dpr[i])\n",
        "            ]) for i in range(self.n_blocks)])\n",
        "        self.prediction = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv2D(1024, 1, use_bias=True),\n",
        "            tf.keras.layers.BatchNormalization(),\n",
        "            act_layer(act),\n",
        "            tf.keras.layers.Dropout(opt.dropout),\n",
        "            tf.keras.layers.Conv2D(opt.n_classes, 1, use_bias=True)\n",
        "        ])\n",
        "        self.model_init()\n",
        "\n",
        "    def model_init(self):\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D):\n",
        "                tf.keras.initializers.VarianceScaling()(layer.kernel)\n",
        "                layer.kernel.trainable = True\n",
        "                if layer.bias is not None:\n",
        "                    layer.bias.assign(tf.zeros_like(layer.bias))\n",
        "                    layer.bias.trainable = True\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = self.stem(inputs) + self.pos_embed\n",
        "        B, C, H, W = x.shape\n",
        "        \n",
        "        for i in range(self.n_blocks):\n",
        "            x = self.backbone[i](x)\n",
        "\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        return tf.squeeze(self.prediction(x), axis=[1, 2])\n",
        "\n",
        "\n",
        "@register_model\n",
        "def vig_ti_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=1000, drop_path_rate=0.0, drop_rate=0.0, num_knn=9, **kwargs):\n",
        "            self.k = num_knn # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.n_blocks = 12 # number of basic blocks in the backbone\n",
        "            self.n_filters = 192 # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.dropout = drop_rate # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['gnn_patch16_224']\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def vig_s_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=1000, drop_path_rate=0.0, drop_rate=0.0, num_knn=9, **kwargs):\n",
        "            self.k = num_knn # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.n_blocks = 16 # number of basic blocks in the backbone\n",
        "            self.n_filters = 320 # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.dropout = drop_rate # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['gnn_patch16_224']\n",
        "    return model\n",
        "\n",
        "\n",
        "@register_model\n",
        "def vig_b_224_gelu(pretrained=False, **kwargs):\n",
        "    class OptInit:\n",
        "        def __init__(self, num_classes=1000, drop_path_rate=0.0, drop_rate=0.0, num_knn=9, **kwargs):\n",
        "            self.k = num_knn # neighbor num (default:9)\n",
        "            self.conv = 'mr' # graph conv layer {edge, mr}\n",
        "            self.act = 'gelu' # activation layer {relu, prelu, leakyrelu, gelu, hswish}\n",
        "            self.norm = 'batch' # batch or instance normalization {batch, instance}\n",
        "            self.bias = True # bias of conv layer True or False\n",
        "            self.n_blocks = 16 # number of basic blocks in the backbone\n",
        "            self.n_filters = 640 # number of channels of deep features\n",
        "            self.n_classes = num_classes # Dimension of out_channels\n",
        "            self.dropout = drop_rate # dropout rate\n",
        "            self.use_dilation = True # use dilated knn or not\n",
        "            self.epsilon = 0.2 # stochastic epsilon for gcn\n",
        "            self.use_stochastic = False # stochastic for gcn, True or False\n",
        "            self.drop_path = drop_path_rate\n",
        "\n",
        "    opt = OptInit(**kwargs)\n",
        "    model = DeepGCN(opt)\n",
        "    model.default_cfg = default_cfgs['gnn_patch16_224']\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG0vhGocIwR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "320dd526-b2fc-4f61-b099-c0ff2332ab1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchprofile\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.9/dist-packages (from torchprofile) (1.7.1+cu101)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.9/dist-packages (from torchprofile) (1.22.4)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.9/dist-packages (from torchprofile) (0.8.2+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.4->torchprofile) (4.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from torchvision>=0.4->torchprofile) (8.4.0)\n",
            "Installing collected packages: torchprofile\n",
            "Successfully installed torchprofile-0.0.4\n"
          ]
        }
      ],
      "source": [
        "!pip install torchprofile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cfG397r4Ozy"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import argparse\n",
        "import time\n",
        "import yaml\n",
        "import os\n",
        "import logging\n",
        "from collections import OrderedDict\n",
        "from contextlib import suppress\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.utils\n",
        "from torch.nn.parallel import DistributedDataParallel as NativeDDP\n",
        "\n",
        "from timm.data import ImageDataset, resolve_data_config, Mixup, FastCollateMixup, AugMixDataset #, create_loader\n",
        "from timm.models import create_model, resume_checkpoint, convert_splitbn_model\n",
        "from timm.utils import *\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
        "from timm.optim import create_optimizer\n",
        "from timm.scheduler import create_scheduler\n",
        "from timm.utils import ApexScaler, NativeScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_WgknOqqgrp"
      },
      "outputs": [],
      "source": [
        "def validate(model, loader, loss_fn, args, amp_autocast=suppress, log_suffix=''):\n",
        "    batch_time_m = AverageMeter()\n",
        "    losses_m = AverageMeter()\n",
        "    top1_m = AverageMeter()\n",
        "    top5_m = AverageMeter()\n",
        "\n",
        "    end = time.time()\n",
        "    last_idx = len(loader) - 1\n",
        "    for batch_idx, (input, target) in enumerate(loader):\n",
        "        last_batch = batch_idx == last_idx\n",
        "        if not args.prefetcher:\n",
        "            input = tf.constant(input)\n",
        "            target = tf.constant(target)\n",
        "        if args.channels_last:\n",
        "            input = tf.transpose(input, [0, 3, 1, 2])\n",
        "        with tf.GradientTape(persistent=False):\n",
        "            model.eval()\n",
        "            # logits = model(input, training=False)\n",
        "            # loss = loss_fn(logits, target)\n",
        "            # acc1, acc5 = accuracy(logits, target, topk=(1, 5))\n",
        "        # losses_m.update(loss.numpy(), input.shape[0])\n",
        "        # top1_m.update(acc1.numpy(), input.shape[0])\n",
        "        # top5_m.update(acc5.numpy(), input.shape[0])\n",
        "        # batch_time_m.update(time.time() - end)\n",
        "        # end = time.time()\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "              output = model(input, training=True)\n",
        "        if isinstance(output, (tuple, list)):\n",
        "              output = output[0]\n",
        "\n",
        "# augmentation reduction\n",
        "        reduce_factor = args.tta\n",
        "        if reduce_factor > 1:\n",
        "            output = tf.math.reduce_mean(tf.signal.frame(output, reduce_factor, reduce_factor), axis=2)\n",
        "            target = target[0:tf.shape(target)[0]:reduce_factor]\n",
        "\n",
        "        loss = loss_fn(output, target)\n",
        "        acc1, acc5 = tf.keras.metrics.top_k_categorical_accuracy(target, output, k=1), tf.keras.metrics.top_k_categorical_accuracy(target, output, k=5)\n",
        "\n",
        "           \n",
        "        if args.distributed:\n",
        "            reduced_loss = reduce_tensor(loss.data, args.world_size)\n",
        "            acc1 = reduce_tensor(acc1, args.world_size)\n",
        "            acc5 = reduce_tensor(acc5, args.world_size)\n",
        "        else:\n",
        "         reduced_loss = loss.data\n",
        "            \n",
        "\n",
        "        tf.distribute.get_replica_context().merge_call(lambda strategy: strategy.experimental_local_results(reduced_loss, acc1, acc5))\n",
        "\n",
        "        losses_m.update(tf.reduce_mean(reduced_loss).numpy(), input.shape[0])\n",
        "        top1_m.update(tf.reduce_mean(acc1).numpy(), output.shape[0])\n",
        "        top5_m.update(tf.reduce_mean(acc5).numpy(), output.shape[0])    \n",
        "\n",
        "            # torch.cuda.synchronize()\n",
        "\n",
        "            # losses_m.update(reduced_loss.item(), input.size(0))\n",
        "            # top1_m.update(acc1.item(), output.size(0))\n",
        "            # top5_m.update(acc5.item(), output.size(0))\n",
        "\n",
        "        batch_time_m.update_state(time.time() - end)\n",
        "        end = time.time()\n",
        "        if (last_batch or batch_idx % args.log_interval == 0):\n",
        "          log_name = 'Test' + log_suffix\n",
        "          loss = losses_m.result().numpy()\n",
        "          top1 = top1_m.result().numpy()\n",
        "          top5 = top5_m.result().numpy()\n",
        "          _logger.info(\n",
        "              '{0}: [{1:>4d}/{2}]  '\n",
        "              'Time: {batch_time.val:.3f} ({batch_time.avg:.3f})  '\n",
        "              'Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '\n",
        "              'Acc@1: {top1.val:>7.4f} ({top1.avg:>7.4f})  '\n",
        "              'Acc@5: {top5.val:>7.4f} ({top5.avg:>7.4f})'.format(\n",
        "                  log_name, batch_idx, last_idx, batch_time=batch_time_m,\n",
        "                  loss=losses_m, top1=top1_m, top5=top5_m))\n",
        "        batch_time_m.reset_states()\n",
        "        losses_m.reset_states()\n",
        "        top1_m.reset_states()\n",
        "        top5_m.reset_states()  \n",
        "\n",
        "    metrics = OrderedDict([('loss', losses_m.avg), ('top1', top1_m.avg), ('top5', top5_m.avg)])\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-ZPIMkyEwac"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from apex import amp\n",
        "    from apex.parallel import DistributedDataParallel as ApexDDP\n",
        "    from apex.parallel import convert_syncbn_model\n",
        "    has_apex = True\n",
        "except ImportError:\n",
        "    has_apex = False\n",
        "\n",
        "has_native_amp = False\n",
        "try:\n",
        "    if getattr(torch.cuda.amp, 'autocast') is not None:\n",
        "        has_native_amp = True\n",
        "except AttributeError:\n",
        "    pass\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "_logger = logging.getLogger('train')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "strategy = tf.distribute.MirroredStrategy()"
      ],
      "metadata": {
        "id": "HGi0g5PFWrHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F52wabibR5m2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88a129b9-a605-4f97-aa07-93f95edd66ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_StoreTrueAction(option_strings=['--evaluate'], dest='evaluate', nargs=0, const=True, default=False, type=None, choices=None, required=False, help='whether evaluate the model', metavar=None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
        "parser.add_argument('data', metavar='DIR', default = '/content/tiny-imagenet-200',\n",
        "                    help='path to dataset')\n",
        "parser.add_argument('--model', default='resnet101', type=str, metavar='MODEL',\n",
        "                    help='Name of model to train (default: \"countception\"')\n",
        "parser.add_argument('--pretrained', action='store_true', default=False,\n",
        "                    help='Start with pretrained version of specified network (if avail)')\n",
        "parser.add_argument('--initial-checkpoint', default='', type=str, metavar='PATH',\n",
        "                    help='Initialize model from this checkpoint (default: none)')\n",
        "parser.add_argument('--resume', default='', type=str, metavar='PATH',\n",
        "                    help='Resume full model and optimizer state from checkpoint (default: none)')\n",
        "parser.add_argument('--no-resume-opt', action='store_true', default=False,\n",
        "                    help='prevent resume of optimizer state when resuming model')\n",
        "parser.add_argument('--num-classes', type=int, default=1000, metavar='N',\n",
        "                    help='number of label classes (default: 1000)')\n",
        "parser.add_argument('--gp', default=None, type=str, metavar='POOL',\n",
        "                    help='Global pool type, one of (fast, avg, max, avgmax, avgmaxc). Model default if None.')\n",
        "parser.add_argument('--img-size', type=int, default=None, metavar='N',\n",
        "                    help='Image patch size (default: None => model default)')\n",
        "parser.add_argument('--crop-pct', default=None, type=float,\n",
        "                    metavar='N', help='Input image center crop percent (for validation only)')\n",
        "parser.add_argument('--mean', type=float, nargs='+', default=None, metavar='MEAN',\n",
        "                    help='Override mean pixel value of dataset')\n",
        "parser.add_argument('--std', type=float, nargs='+', default=None, metavar='STD',\n",
        "                    help='Override std deviation of of dataset')\n",
        "parser.add_argument('--interpolation', default='', type=str, metavar='NAME',\n",
        "                    help='Image resize interpolation type (overrides model)')\n",
        "parser.add_argument('-b', '--batch-size', type=int, default=32, metavar='N',\n",
        "                    help='input batch size for training (default: 32)')\n",
        "parser.add_argument('-vb', '--validation-batch-size-multiplier', type=int, default=1, metavar='N',\n",
        "                    help='ratio of validation batch size to training batch size (default: 1)')\n",
        "\n",
        "# Optimizer parameters\n",
        "parser.add_argument('--opt', default='sgd', type=str, metavar='OPTIMIZER',\n",
        "                    help='Optimizer (default: \"sgd\"')\n",
        "parser.add_argument('--opt-eps', default=None, type=float, metavar='EPSILON',\n",
        "                    help='Optimizer Epsilon (default: None, use opt default)')\n",
        "parser.add_argument('--opt-betas', default=None, type=float, nargs='+', metavar='BETA',\n",
        "                    help='Optimizer Betas (default: None, use opt default)')\n",
        "parser.add_argument('--momentum', type=float, default=0.9, metavar='M',\n",
        "                    help='Optimizer momentum (default: 0.9)')\n",
        "parser.add_argument('--weight-decay', type=float, default=0.0001,\n",
        "                    help='weight decay (default: 0.0001)')\n",
        "parser.add_argument('--clip-grad', type=float, default=None, metavar='NORM',\n",
        "                    help='Clip gradient norm (default: None, no clipping)')\n",
        "\n",
        "\n",
        "\n",
        "# Learning rate schedule parameters\n",
        "parser.add_argument('--sched', default='step', type=str, metavar='SCHEDULER',\n",
        "                    help='LR scheduler (default: \"step\"')\n",
        "parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
        "                    help='learning rate (default: 0.01)')\n",
        "parser.add_argument('--lr-noise', type=float, nargs='+', default=None, metavar='pct, pct',\n",
        "                    help='learning rate noise on/off epoch percentages')\n",
        "parser.add_argument('--lr-noise-pct', type=float, default=0.67, metavar='PERCENT',\n",
        "                    help='learning rate noise limit percent (default: 0.67)')\n",
        "parser.add_argument('--lr-noise-std', type=float, default=1.0, metavar='STDDEV',\n",
        "                    help='learning rate noise std-dev (default: 1.0)')\n",
        "parser.add_argument('--lr-cycle-mul', type=float, default=1.0, metavar='MULT',\n",
        "                    help='learning rate cycle len multiplier (default: 1.0)')\n",
        "parser.add_argument('--lr-cycle-limit', type=int, default=1, metavar='N',\n",
        "                    help='learning rate cycle limit')\n",
        "parser.add_argument('--warmup-lr', type=float, default=0.0001, metavar='LR',\n",
        "                    help='warmup learning rate (default: 0.0001)')\n",
        "parser.add_argument('--min-lr', type=float, default=1e-5, metavar='LR',\n",
        "                    help='lower lr bound for cyclic schedulers that hit 0 (1e-5)')\n",
        "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
        "                    help='number of epochs to train (default: 2)')\n",
        "parser.add_argument('--start-epoch', default=None, type=int, metavar='N',\n",
        "                    help='manual epoch number (useful on restarts)')\n",
        "parser.add_argument('--decay-epochs', type=float, default=30, metavar='N',\n",
        "                    help='epoch interval to decay LR')\n",
        "parser.add_argument('--warmup-epochs', type=int, default=3, metavar='N',\n",
        "                    help='epochs to warmup LR, if scheduler supports')\n",
        "parser.add_argument('--cooldown-epochs', type=int, default=10, metavar='N',\n",
        "                    help='epochs to cooldown LR at min_lr, after cyclic schedule ends')\n",
        "parser.add_argument('--patience-epochs', type=int, default=10, metavar='N',\n",
        "                    help='patience epochs for Plateau LR scheduler (default: 10')\n",
        "parser.add_argument('--decay-rate', '--dr', type=float, default=0.1, metavar='RATE',\n",
        "                    help='LR decay rate (default: 0.1)')\n",
        "\n",
        "# Augmentation & regularization parameters\n",
        "parser.add_argument('--no-aug', action='store_true', default=False,\n",
        "                    help='Disable all training augmentation, override other train aug args')\n",
        "parser.add_argument('--repeated-aug', action='store_true')\n",
        "parser.add_argument('--scale', type=float, nargs='+', default=[0.08, 1.0], metavar='PCT',\n",
        "                    help='Random resize scale (default: 0.08 1.0)')\n",
        "parser.add_argument('--ratio', type=float, nargs='+', default=[3./4., 4./3.], metavar='RATIO',\n",
        "                    help='Random resize aspect ratio (default: 0.75 1.33)')\n",
        "parser.add_argument('--hflip', type=float, default=0.5,\n",
        "                    help='Horizontal flip training aug probability')\n",
        "parser.add_argument('--vflip', type=float, default=0.,\n",
        "                    help='Vertical flip training aug probability')\n",
        "parser.add_argument('--color-jitter', type=float, default=0.4, metavar='PCT',\n",
        "                    help='Color jitter factor (default: 0.4)')\n",
        "parser.add_argument('--aa', type=str, default=None, metavar='NAME',\n",
        "                    help='Use AutoAugment policy. \"v0\" or \"original\". (default: None)'),\n",
        "parser.add_argument('--aug-splits', type=int, default=0,\n",
        "                    help='Number of augmentation splits (default: 0, valid: 0 or >=2)')\n",
        "parser.add_argument('--jsd', action='store_true', default=False,\n",
        "                    help='Enable Jensen-Shannon Divergence + CE loss. Use with `--aug-splits`.')\n",
        "parser.add_argument('--reprob', type=float, default=0., metavar='PCT',\n",
        "                    help='Random erase prob (default: 0.)')\n",
        "parser.add_argument('--remode', type=str, default='const',\n",
        "                    help='Random erase mode (default: \"const\")')\n",
        "parser.add_argument('--recount', type=int, default=1,\n",
        "                    help='Random erase count (default: 1)')\n",
        "parser.add_argument('--resplit', action='store_true', default=False,\n",
        "                    help='Do not random erase first (clean) augmentation split')\n",
        "parser.add_argument('--mixup', type=float, default=0.0,\n",
        "                    help='mixup alpha, mixup enabled if > 0. (default: 0.)')\n",
        "parser.add_argument('--cutmix', type=float, default=0.0,\n",
        "                    help='cutmix alpha, cutmix enabled if > 0. (default: 0.)')\n",
        "parser.add_argument('--cutmix-minmax', type=float, nargs='+', default=None,\n",
        "                    help='cutmix min/max ratio, overrides alpha and enables cutmix if set (default: None)')\n",
        "parser.add_argument('--mixup-prob', type=float, default=1.0,\n",
        "                    help='Probability of performing mixup or cutmix when either/both is enabled')\n",
        "parser.add_argument('--mixup-switch-prob', type=float, default=0.5,\n",
        "                    help='Probability of switching to cutmix when both mixup and cutmix enabled')\n",
        "parser.add_argument('--mixup-mode', type=str, default='batch',\n",
        "                    help='How to apply mixup/cutmix params. Per \"batch\", \"pair\", or \"elem\"')\n",
        "parser.add_argument('--mixup-off-epoch', default=0, type=int, metavar='N',\n",
        "                    help='Turn off mixup after this epoch, disabled if 0 (default: 0)')\n",
        "parser.add_argument('--smoothing', type=float, default=0.1,\n",
        "                    help='Label smoothing (default: 0.1)')\n",
        "parser.add_argument('--train-interpolation', type=str, default='random',\n",
        "                    help='Training interpolation (random, bilinear, bicubic default: \"random\")')\n",
        "parser.add_argument('--drop', type=float, default=0.0, metavar='PCT',\n",
        "                    help='Dropout rate (default: 0.)')\n",
        "parser.add_argument('--drop-connect', type=float, default=None, metavar='PCT',\n",
        "                    help='Drop connect rate, DEPRECATED, use drop-path (default: None)')\n",
        "parser.add_argument('--drop-path', type=float, default=None, metavar='PCT',\n",
        "                    help='Drop path rate (default: None)')\n",
        "parser.add_argument('--drop-block', type=float, default=None, metavar='PCT',\n",
        "                    help='Drop block rate (default: None)')\n",
        "\n",
        "# Batch norm parameters (only works with gen_efficientnet based models currently)\n",
        "parser.add_argument('--bn-tf', action='store_true', default=False,\n",
        "                    help='Use Tensorflow BatchNorm defaults for models that support it (default: False)')\n",
        "parser.add_argument('--bn-momentum', type=float, default=None,\n",
        "                    help='BatchNorm momentum override (if not None)')\n",
        "parser.add_argument('--bn-eps', type=float, default=None,\n",
        "                    help='BatchNorm epsilon override (if not None)')\n",
        "parser.add_argument('--sync-bn', action='store_true',\n",
        "                    help='Enable NVIDIA Apex or Torch synchronized BatchNorm.')\n",
        "parser.add_argument('--dist-bn', type=str, default='',\n",
        "                    help='Distribute BatchNorm stats between nodes after each epoch (\"broadcast\", \"reduce\", or \"\")')\n",
        "parser.add_argument('--split-bn', action='store_true',\n",
        "                    help='Enable separate BN layers per augmentation split.')\n",
        "\n",
        "# Model Exponential Moving Average\n",
        "parser.add_argument('--model-ema', action='store_true', default=False,\n",
        "                    help='Enable tracking moving average of model weights')\n",
        "parser.add_argument('--model-ema-force-cpu', action='store_true', default=False,\n",
        "                    help='Force ema to be tracked on CPU, rank=0 node only. Disables EMA validation.')\n",
        "parser.add_argument('--model-ema-decay', type=float, default=0.9998,\n",
        "                    help='decay factor for model weights moving average (default: 0.9998)')\n",
        "\n",
        "# Misc\n",
        "parser.add_argument('--seed', type=int, default=42, metavar='S',\n",
        "                    help='random seed (default: 42)')\n",
        "parser.add_argument('--log-interval', type=int, default=50, metavar='N',\n",
        "                    help='how many batches to wait before logging training status')\n",
        "parser.add_argument('--recovery-interval', type=int, default=0, metavar='N',\n",
        "                    help='how many batches to wait before writing recovery checkpoint')\n",
        "parser.add_argument('-j', '--workers', type=int, default=4, metavar='N',\n",
        "                    help='how many training processes to use (default: 1)')\n",
        "parser.add_argument('--num-gpu', type=int, default=1,\n",
        "                    help='Number of GPUS to use')\n",
        "parser.add_argument('--save-images', action='store_true', default=False,\n",
        "                    help='save images of input bathes every log interval for debugging')\n",
        "parser.add_argument('--amp', action='store_true', default=False,\n",
        "                    help='use NVIDIA Apex AMP or Native AMP for mixed precision training')\n",
        "parser.add_argument('--apex-amp', action='store_true', default=False,\n",
        "                    help='Use NVIDIA Apex AMP mixed precision')\n",
        "parser.add_argument('--native-amp', action='store_true', default=False,\n",
        "                    help='Use Native Torch AMP mixed precision')\n",
        "parser.add_argument('--channels-last', action='store_true', default=False,\n",
        "                    help='Use channels_last memory layout')\n",
        "parser.add_argument('--pin-mem', action='store_true', default=False,\n",
        "                    help='Pin CPU memory in DataLoader for more efficient (sometimes) transfer to GPU.')\n",
        "parser.add_argument('--no-prefetcher', action='store_true', default=False,\n",
        "                    help='disable fast prefetcher')\n",
        "parser.add_argument('--output', default='', type=str, metavar='PATH',\n",
        "                    help='path to output folder (default: none, current dir)')\n",
        "parser.add_argument('--eval-metric', default='top1', type=str, metavar='EVAL_METRIC',\n",
        "                    help='Best metric (default: \"top1\"')\n",
        "parser.add_argument('--tta', type=int, default=0, metavar='N',\n",
        "                    help='Test/inference time augmentation (oversampling) factor. 0=None (default: 0)')\n",
        "parser.add_argument(\"--local_rank\", default=0, type=int)\n",
        "parser.add_argument('--use-multi-epochs-loader', action='store_true', default=False,\n",
        "                    help='use the multi-epochs-loader to save time at the beginning of every epoch')\n",
        "# for huawei cloud\n",
        "parser.add_argument(\"--init_method\", default='env://', type=str)\n",
        "parser.add_argument(\"--train_url\", type=str)\n",
        "# newly added\n",
        "parser.add_argument('--attn_ratio', type=float, default=1.,\n",
        "                    help='attention ratio')\n",
        "#parser.add_argument(\"--pretrain_path\", default=None, type=str)\n",
        "parser.add_argument(\"--evaluate\", action='store_true', default=False,\n",
        "                    help='whether evaluate the model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-addons==0.16.1"
      ],
      "metadata": {
        "id": "Z4H7Z3IVesLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cb9fb99-912c-4447-cd48-8979eb00302c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons==0.16.1\n",
            "  Downloading tensorflow_addons-0.16.1-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7\n",
            "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (6.4.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons==0.16.1) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow-addons==0.16.1) (3.15.0)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.16.1 typeguard-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow_addons.losses import SigmoidFocalCrossEntropy"
      ],
      "metadata": {
        "id": "Rv--2aNXcPFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def JsdCrossEntropy(num_splits, smoothing):\n",
        "    def loss(y_true, y_pred):\n",
        "        loss_fn = CategoricalCrossentropy(label_smoothing=smoothing)\n",
        "        js_div = 0.0\n",
        "        for i in range(num_splits):\n",
        "            ys = y_true[:, i, :]\n",
        "            yp = y_pred[:, i, :]\n",
        "            js_div += tf.distributions.kl_divergence(\n",
        "                tf.distributions.Categorical(probs=ys),\n",
        "                tf.distributions.Categorical(probs=yp),\n",
        "            ) / num_splits\n",
        "        return loss_fn(y_true, y_pred) - js_div\n",
        "    return loss"
      ],
      "metadata": {
        "id": "EoN376rDfU1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftTargetCrossEntropy(tf.keras.losses.Loss):\n",
        "    def __init__(self):\n",
        "        super(SoftTargetCrossEntropy, self).__init__()\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        loss = -tf.reduce_sum(y_true * tf.math.log(y_pred), axis=-1)\n",
        "        return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "bk7yiDOxgK8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LabelSmoothingCrossEntropy(tf.keras.losses.Loss):\n",
        "    def __init__(self, smoothing=0.1):\n",
        "        super(LabelSmoothingCrossEntropy, self).__init__()\n",
        "        self.smoothing = smoothing\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        num_classes = y_pred.shape[-1]\n",
        "        y_true = tf.cast(y_true, y_pred.dtype)\n",
        "        \n",
        "          \n",
        "        confidence = 1.0 - self.smoothing\n",
        "        smooth_labels = y_true * confidence + (1.0 - confidence) / num_classes\n",
        "        smooth_labels = tf.cast(smooth_labels, tf.int32)\n",
        "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=smooth_labels, y_pred=y_pred, from_logits=False)\n",
        "        return tf.reduce_mean(loss)\n"
      ],
      "metadata": {
        "id": "0NwyCVcZg9_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelEMA(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, model, decay, device='cpu'):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.decay = decay\n",
        "        self.device = device\n",
        "        self.ema_model = tf.keras.models.clone_model(model)\n",
        "        self.ema_model.set_weights(model.get_weights())\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.update_ema_variables()\n",
        "\n",
        "    def update_ema_variables(self):\n",
        "        ema_variables = self.ema_model.variables\n",
        "        for var, ema_var in zip(self.model.variables, ema_variables):\n",
        "            ema_var.assign_sub((ema_var - var) * (1 - self.decay))\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        self.model.set_weights(self.ema_model.get_weights())"
      ],
      "metadata": {
        "id": "liNYjEb7odfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_splitbn_model(model, num_splits):\n",
        "    for layer in model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.BatchNormalization):\n",
        "            layer = tf.keras.layers.experimental.SyncBatchNormalization(num_groups=num_splits)(layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "hmfoma9YJTSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-model-optimization\n"
      ],
      "metadata": {
        "id": "dMP-Gnxlh9nI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb96a7c-33a3-4740-a098-5f4a5a4865c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-model-optimization\n",
            "  Downloading tensorflow_model_optimization-0.7.4-py2.py3-none-any.whl (240 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (0.1.8)\n",
            "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.4.0)\n",
            "Collecting numpy~=1.23\n",
            "  Downloading numpy-1.24.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six~=1.14 in /usr/local/lib/python3.9/dist-packages (from tensorflow-model-optimization) (1.16.0)\n",
            "Installing collected packages: numpy, tensorflow-model-optimization\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.15.1 requires torch==2.0.0, but you have torch 1.7.1+cu101 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.24.3 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.24.3 tensorflow-model-optimization-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "@tf.function\n",
        "def get_macs(model, inputs):\n",
        "    model(inputs)\n",
        "    return tf.compat.v1.trainable_variables(scope=None, graph=tf.compat.v1.get_default_graph())\n"
      ],
      "metadata": {
        "id": "3B3JleVHh4Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import argparse\n",
        "import time\n",
        "import yaml\n",
        "import os\n",
        "import logging\n",
        "from collections import OrderedDict\n",
        "from contextlib import suppress\n",
        "from datetime import datetime\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.utils\n",
        "from torch.nn.parallel import DistributedDataParallel as NativeDDP\n",
        "\n",
        "from timm.data import ImageDataset, resolve_data_config, Mixup, FastCollateMixup, AugMixDataset #, create_loader\n",
        "from timm.models import create_model, resume_checkpoint, convert_splitbn_model\n",
        "from timm.utils import *\n",
        "from timm.loss import LabelSmoothingCrossEntropy, SoftTargetCrossEntropy, JsdCrossEntropy\n",
        "from timm.optim import create_optimizer\n",
        "from timm.scheduler import create_scheduler\n",
        "from timm.utils import ApexScaler, NativeScaler"
      ],
      "metadata": {
        "id": "cINSMzNscccT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9_J_7yt0voM"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    setup_default_logging()\n",
        "    args, remaining = parser.parse_known_args()\n",
        "    args_text = yaml.safe_dump(args.__dict__, default_flow_style=False)\n",
        "\n",
        "    args.prefetcher = not args.no_prefetcher\n",
        "    args.distributed = False\n",
        "    if 'WORLD_SIZE' in os.environ:\n",
        "        args.distributed = int(os.environ['WORLD_SIZE']) > 1\n",
        "        if args.distributed and args.num_gpu > 1:\n",
        "            _logger.warning(\n",
        "                'Using more than one GPU per process in distributed mode is not allowed.Setting num_gpu to 1.')\n",
        "            args.num_gpu = 1\n",
        "\n",
        "    args.device = 'cuda:0'\n",
        "    args.world_size = 1\n",
        "    args.rank = 0  # global rank\n",
        "    if args.distributed:\n",
        "        args.num_gpu = 1\n",
        "        args.device = 'cuda:%d' % args.local_rank\n",
        "        torch.cuda.set_device(args.local_rank)\n",
        "        args.world_size = int(os.environ['WORLD_SIZE'])\n",
        "        args.rank = int(os.environ['RANK'])\n",
        "        torch.distributed.init_process_group(backend='nccl', init_method=args.init_method, rank=args.rank, world_size=args.world_size)\n",
        "        args.world_size = torch.distributed.get_world_size()\n",
        "        args.rank = torch.distributed.get_rank()\n",
        "    assert args.rank >= 0\n",
        "\n",
        "    if args.distributed:\n",
        "        _logger.info('Training in distributed mode with multiple processes, 1 GPU per process. Process %d, total %d.'\n",
        "                     % (args.rank, args.world_size))\n",
        "    else:\n",
        "        _logger.info('Training with a single process on %d GPUs.' % args.num_gpu)\n",
        "\n",
        "    torch.manual_seed(args.seed + args.rank)\n",
        "\n",
        "    model = create_model(\n",
        "        args.model,\n",
        "        pretrained=args.pretrained,\n",
        "        num_classes=args.num_classes,\n",
        "        drop_rate=args.drop,\n",
        "        drop_connect_rate=args.drop_connect,  # DEPRECATED, use drop_path\n",
        "        drop_path_rate=args.drop_path,\n",
        "        drop_block_rate=args.drop_block,\n",
        "        global_pool=args.gp,\n",
        "        #bn_tf=args.bn_tf,\n",
        "        bn_momentum=args.bn_momentum,\n",
        "        bn_eps=args.bn_eps,\n",
        "        checkpoint_path=args.initial_checkpoint)\n",
        "        \n",
        "    ################## pretrain ############\n",
        "    # if args.pretrain_path is not None:\n",
        "    #     print('Loading:', args.pretrain_path)\n",
        "    #     state_dict = torch.load(args.pretrain_path)\n",
        "    #     model.load_state_dict(state_dict, strict=False)\n",
        "    #     print('Pretrain weights loaded.')\n",
        "    ################### flops #################\n",
        "    # print(model)\n",
        "    if hasattr(model, 'default_cfg'):\n",
        "        default_cfg = model.default_cfg\n",
        "        input_size = [1] + list(default_cfg['input_size'])\n",
        "    else:\n",
        "        input_size = [1, 3, 224, 224]\n",
        "    input = torch.randn(input_size)#.cuda()\n",
        "    \n",
        "    from torchprofile import profile_macs\n",
        "    model.eval()\n",
        "    macs = profile_macs(model, input)\n",
        "    model.train()\n",
        "    print('model flops:', macs, 'input_size:', input_size)\n",
        "    ##########################################\n",
        "    \n",
        "    if args.local_rank == 0:\n",
        "        _logger.info('Model %s created, param count: %d' %\n",
        "                     (args.model, sum([m.numel() for m in model.parameters()])))\n",
        "\n",
        "    data_config = resolve_data_config(vars(args), model=model, verbose=args.local_rank == 0)\n",
        "\n",
        "    num_aug_splits = 0\n",
        "    if args.aug_splits > 0:\n",
        "        assert args.aug_splits > 1, 'A split of 1 makes no sense'\n",
        "        num_aug_splits = args.aug_splits\n",
        "\n",
        "    if args.split_bn:\n",
        "        assert num_aug_splits > 1 or args.resplit\n",
        "        model = convert_splitbn_model(model, max(num_aug_splits, 2))\n",
        "\n",
        "    use_amp = None\n",
        "    if args.amp:\n",
        "        # for backwards compat, `--amp` arg tries apex before native amp\n",
        "        if has_apex:\n",
        "            args.apex_amp = True\n",
        "        elif has_native_amp:\n",
        "            args.native_amp = True\n",
        "    if args.apex_amp and has_apex:\n",
        "        use_amp = 'apex'\n",
        "    elif args.native_amp and has_native_amp:\n",
        "        use_amp = 'native'\n",
        "    elif args.apex_amp or args.native_amp:\n",
        "        _logger.warning(\"Neither APEX or native Torch AMP is available, using float32. \"\n",
        "                        \"Install NVIDA apex or upgrade to PyTorch 1.6\")\n",
        "\n",
        "    if args.num_gpu > 1:\n",
        "        if use_amp == 'apex':\n",
        "            _logger.warning(\n",
        "                'Apex AMP does not work well with nn.DataParallel, disabling. Use DDP or Torch AMP.')\n",
        "            use_amp = None\n",
        "        model = nn.DataParallel(model, device_ids=list(range(args.num_gpu))).cuda()\n",
        "        assert not args.channels_last, \"Channels last not supported with DP, use DDP.\"\n",
        "    else:\n",
        "        model.cuda()\n",
        "        if args.channels_last:\n",
        "            model = model.to(memory_format=torch.channels_last)\n",
        "\n",
        "    optimizer = create_optimizer(args, model)\n",
        "\n",
        "    amp_autocast = suppress  # do nothing\n",
        "    loss_scaler = None\n",
        "    if use_amp == 'apex':\n",
        "        model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
        "        loss_scaler = ApexScaler()\n",
        "        if args.local_rank == 0:\n",
        "            _logger.info('Using NVIDIA APEX AMP. Training in mixed precision.')\n",
        "    elif use_amp == 'native':\n",
        "        amp_autocast = torch.cuda.amp.autocast\n",
        "        loss_scaler = NativeScaler()\n",
        "        if args.local_rank == 0:\n",
        "            _logger.info('Using native Torch AMP. Training in mixed precision.')\n",
        "    else:\n",
        "        if args.local_rank == 0:\n",
        "            _logger.info('AMP not enabled. Training in float32.')\n",
        "\n",
        "    # optionally resume from a checkpoint\n",
        "    resume_epoch = None\n",
        "    if args.resume:\n",
        "        resume_epoch = resume_checkpoint(\n",
        "            model, args.resume,\n",
        "            optimizer=None if args.no_resume_opt else optimizer,\n",
        "            loss_scaler=None if args.no_resume_opt else loss_scaler,\n",
        "            log_info=args.local_rank == 0)\n",
        "\n",
        "    model_ema = None\n",
        "    if args.model_ema:\n",
        "        # Important to create EMA model after cuda(), DP wrapper, and AMP but before SyncBN and DDP wrapper\n",
        "        model_ema = ModelEma(\n",
        "            model,\n",
        "            decay=args.model_ema_decay,\n",
        "            device='cpu' if args.model_ema_force_cpu else '',\n",
        "            resume=args.resume)\n",
        "\n",
        "    if args.distributed:\n",
        "        if args.sync_bn:\n",
        "            assert not args.split_bn\n",
        "            try:\n",
        "                if has_apex and use_amp != 'native':\n",
        "                    # Apex SyncBN preferred unless native amp is activated\n",
        "                    model = convert_syncbn_model(model)\n",
        "                else:\n",
        "                    model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
        "                if args.local_rank == 0:\n",
        "                    _logger.info(\n",
        "                        'Converted model to use Synchronized BatchNorm. WARNING: You may have issues if using '\n",
        "                        'zero initialized BN layers (enabled by default for ResNets) while sync-bn enabled.')\n",
        "            except Exception as e:\n",
        "                _logger.error('Failed to enable Synchronized BatchNorm. Install Apex or Torch >= 1.1')\n",
        "        if has_apex and use_amp != 'native':\n",
        "            # Apex DDP preferred unless native amp is activated\n",
        "            if args.local_rank == 0:\n",
        "                _logger.info(\"Using NVIDIA APEX DistributedDataParallel.\")\n",
        "            model = ApexDDP(model, delay_allreduce=True)\n",
        "        else:\n",
        "            if args.local_rank == 0:\n",
        "                _logger.info(\"Using native Torch DistributedDataParallel.\")\n",
        "            model = NativeDDP(model, device_ids=[args.local_rank])  # can use device str in Torch >= 1.1\n",
        "        # NOTE: EMA model does not need to be wrapped by DDP\n",
        "\n",
        "    lr_scheduler, num_epochs = create_scheduler(args, optimizer)\n",
        "    start_epoch = 0\n",
        "    if args.start_epoch is not None:\n",
        "        # a specified start_epoch will always override the resume epoch\n",
        "        start_epoch = args.start_epoch\n",
        "    elif resume_epoch is not None:\n",
        "        start_epoch = resume_epoch\n",
        "    if lr_scheduler is not None and start_epoch > 0:\n",
        "        lr_scheduler.step(start_epoch)\n",
        "\n",
        "    if args.local_rank == 0:\n",
        "        _logger.info('Scheduled epochs: {}'.format(num_epochs))\n",
        "\n",
        "    train_dir = \"/content/drive/Shareddrives/rs assignment1/imagenette2/train\"\n",
        "    \n",
        "    dataset_train = ImageDataset(train_dir)\n",
        "\n",
        "    collate_fn = None\n",
        "    mixup_fn = None\n",
        "    mixup_active = args.mixup > 0 or args.cutmix > 0. or args.cutmix_minmax is not None\n",
        "    if mixup_active:\n",
        "        mixup_args = dict(\n",
        "            mixup_alpha=args.mixup, cutmix_alpha=args.cutmix, cutmix_minmax=args.cutmix_minmax,\n",
        "            prob=args.mixup_prob, switch_prob=args.mixup_switch_prob, mode=args.mixup_mode,\n",
        "            label_smoothing=args.smoothing, num_classes=args.num_classes)\n",
        "        if args.prefetcher:\n",
        "            assert not num_aug_splits  # collate conflict (need to support deinterleaving in collate mixup)\n",
        "            collate_fn = FastCollateMixup(**mixup_args)\n",
        "        else:\n",
        "            mixup_fn = Mixup(**mixup_args)\n",
        "\n",
        "    if num_aug_splits > 1:\n",
        "        dataset_train = AugMixDataset(dataset_train, num_splits=num_aug_splits)\n",
        "\n",
        "    train_interpolation = args.train_interpolation\n",
        "    if args.no_aug or not train_interpolation:\n",
        "        train_interpolation = data_config['interpolation']\n",
        "    loader_train = create_loader(\n",
        "        dataset_train,\n",
        "        input_size=data_config['input_size'],\n",
        "        batch_size=args.batch_size,\n",
        "        is_training=True,\n",
        "        use_prefetcher=args.prefetcher,\n",
        "        no_aug=args.no_aug,\n",
        "        re_prob=args.reprob,\n",
        "        re_mode=args.remode,\n",
        "        re_count=args.recount,\n",
        "        re_split=args.resplit,\n",
        "        scale=args.scale,\n",
        "        ratio=args.ratio,\n",
        "        hflip=args.hflip,\n",
        "        vflip=args.vflip,\n",
        "        color_jitter=args.color_jitter,\n",
        "        auto_augment=args.aa,\n",
        "        num_aug_splits=num_aug_splits,\n",
        "        interpolation=train_interpolation,\n",
        "        mean=data_config['mean'],\n",
        "        std=data_config['std'],\n",
        "        #num_workers=args.workers,\n",
        "        distributed=args.distributed,\n",
        "        collate_fn=collate_fn,\n",
        "        pin_memory=args.pin_mem,\n",
        "        use_multi_epochs_loader=args.use_multi_epochs_loader,\n",
        "        repeated_aug=args.repeated_aug\n",
        "    )\n",
        "\n",
        "    eval_dir = \"/content/drive/Shareddrives/rs assignment1/imagenette2/val\"\n",
        "    \n",
        "    dataset_eval = ImageDataset(eval_dir)\n",
        "\n",
        "    loader_eval = create_loader(\n",
        "        dataset_eval,\n",
        "        input_size=data_config['input_size'],\n",
        "        batch_size=args.validation_batch_size_multiplier * args.batch_size,\n",
        "        is_training=False,\n",
        "        use_prefetcher=args.prefetcher,\n",
        "        interpolation=data_config['interpolation'],\n",
        "        mean=data_config['mean'],\n",
        "        std=data_config['std'],\n",
        "        #num_workers=args.workers,\n",
        "        distributed=args.distributed,\n",
        "        crop_pct=data_config['crop_pct'],\n",
        "        pin_memory=args.pin_mem,\n",
        "    )\n",
        "\n",
        "    if args.jsd:\n",
        "        assert num_aug_splits > 1  # JSD only valid with aug splits set\n",
        "        train_loss_fn = JsdCrossEntropy(num_splits=num_aug_splits, smoothing=args.smoothing).cuda()\n",
        "    elif mixup_active:\n",
        "        # smoothing is handled with mixup target transform\n",
        "        train_loss_fn = SoftTargetCrossEntropy().cuda()\n",
        "    elif args.smoothing:\n",
        "        train_loss_fn = LabelSmoothingCrossEntropy(smoothing=args.smoothing).cuda()\n",
        "    else:\n",
        "        train_loss_fn = nn.CrossEntropyLoss().cuda()\n",
        "    validate_loss_fn = nn.CrossEntropyLoss().cuda()\n",
        "    \n",
        "    if args.evaluate:\n",
        "        eval_metrics = validate(model, loader_eval, validate_loss_fn, args, amp_autocast=amp_autocast)\n",
        "        print(eval_metrics)\n",
        "        return\n",
        "    \n",
        "    eval_metric = args.eval_metric\n",
        "    best_metric = None\n",
        "    best_epoch = None\n",
        "    saver = None\n",
        "    output_dir = ''\n",
        "    if args.local_rank == 0:\n",
        "        output_base = args.output if args.output else './output'\n",
        "        exp_name = '-'.join([\n",
        "            datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
        "            args.model,\n",
        "            str(data_config['input_size'][-1])\n",
        "        ])\n",
        "        output_dir = get_outdir(output_base, 'train', exp_name)\n",
        "        decreasing = True if eval_metric == 'loss' else False\n",
        "        saver = CheckpointSaver(\n",
        "            model=model, optimizer=optimizer, args=args, model_ema=model_ema, amp_scaler=loss_scaler,\n",
        "            checkpoint_dir=output_dir, recovery_dir=output_dir, decreasing=decreasing)\n",
        "        with open(os.path.join(output_dir, 'args.yaml'), 'w') as f:\n",
        "            f.write(args_text)\n",
        "\n",
        "    try:\n",
        "        for epoch in range(start_epoch, num_epochs):\n",
        "            if args.distributed:\n",
        "                loader_train.sampler.set_epoch(epoch)\n",
        "\n",
        "            train_metrics = train_epoch(\n",
        "                epoch, model, loader_train, optimizer, train_loss_fn, args,\n",
        "                lr_scheduler=lr_scheduler, saver=saver, output_dir=output_dir,\n",
        "                amp_autocast=amp_autocast, loss_scaler=loss_scaler, model_ema=model_ema, mixup_fn=mixup_fn)\n",
        "\n",
        "            if args.distributed and args.dist_bn in ('broadcast', 'reduce'):\n",
        "                if args.local_rank == 0:\n",
        "                    _logger.info(\"Distributing BatchNorm running means and vars\")\n",
        "                distribute_bn(model, args.world_size, args.dist_bn == 'reduce')\n",
        "\n",
        "            eval_metrics = validate(model, loader_eval, validate_loss_fn, args, amp_autocast=amp_autocast)\n",
        "\n",
        "            if model_ema is not None and not args.model_ema_force_cpu:\n",
        "                if args.distributed and args.dist_bn in ('broadcast', 'reduce'):\n",
        "                    distribute_bn(model_ema, args.world_size, args.dist_bn == 'reduce')\n",
        "                ema_eval_metrics = validate(\n",
        "                    model_ema.ema, loader_eval, validate_loss_fn, args, amp_autocast=amp_autocast, log_suffix=' (EMA)')\n",
        "                eval_metrics = ema_eval_metrics\n",
        "\n",
        "            if lr_scheduler is not None:\n",
        "                # step LR for next epoch\n",
        "                lr_scheduler.step(epoch + 1, eval_metrics[eval_metric])\n",
        "\n",
        "            update_summary(\n",
        "                epoch, train_metrics, eval_metrics, os.path.join(output_dir, 'summary.csv'),\n",
        "                write_header=best_metric is None)\n",
        "\n",
        "            if saver is not None:\n",
        "                # save proper checkpoint with eval metric\n",
        "                save_metric = eval_metrics[eval_metric]\n",
        "                best_metric, best_epoch = saver.save_checkpoint(epoch, metric=save_metric)\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "    if best_metric is not None:\n",
        "        _logger.info('*** Best metric: {0} (epoch {1})'.format(best_metric, best_epoch))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "        epoch, model, loader, optimizer, loss_fn, args,\n",
        "        lr_scheduler=None, saver=None, output_dir='', amp_autocast=suppress,\n",
        "        loss_scaler=None, model_ema=None, mixup_fn=None):\n",
        "\n",
        "    if args.mixup_off_epoch and epoch >= args.mixup_off_epoch:\n",
        "        if args.prefetcher and loader.mixup_enabled:\n",
        "            loader.mixup_enabled = False\n",
        "        elif mixup_fn is not None:\n",
        "            mixup_fn.mixup_enabled = False\n",
        "\n",
        "    second_order = hasattr(optimizer, 'is_second_order') and optimizer.is_second_order\n",
        "    batch_time_m = AverageMeter()\n",
        "    data_time_m = AverageMeter()\n",
        "    losses_m = AverageMeter()\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    last_idx = len(loader) - 1\n",
        "    num_updates = epoch * len(loader)\n",
        "    for batch_idx, (input, target) in enumerate(loader):\n",
        "        last_batch = batch_idx == last_idx\n",
        "        data_time_m.update(time.time() - end)\n",
        "        if not args.prefetcher:\n",
        "            input, target = input.cuda(), target.cuda()\n",
        "            if mixup_fn is not None:\n",
        "                input, target = mixup_fn(input, target)\n",
        "        if args.channels_last:\n",
        "            input = input.contiguous(memory_format=torch.channels_last)\n",
        "\n",
        "        with amp_autocast():\n",
        "            output = model(input)\n",
        "            loss = loss_fn(output, target)\n",
        "\n",
        "        if not args.distributed:\n",
        "            losses_m.update(loss.item(), input.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        if loss_scaler is not None:\n",
        "            loss_scaler(\n",
        "                loss, optimizer, clip_grad=args.clip_grad, parameters=model.parameters(), create_graph=second_order)\n",
        "        else:\n",
        "            loss.backward(create_graph=second_order)\n",
        "            if args.clip_grad is not None:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.clip_grad)\n",
        "            optimizer.step()\n",
        "\n",
        "        torch.cuda.synchronize()\n",
        "        if model_ema is not None:\n",
        "            model_ema.update(model)\n",
        "        num_updates += 1\n",
        "\n",
        "        batch_time_m.update(time.time() - end)\n",
        "        if last_batch or batch_idx % args.log_interval == 0:\n",
        "            lrl = [param_group['lr'] for param_group in optimizer.param_groups]\n",
        "            lr = sum(lrl) / len(lrl)\n",
        "\n",
        "            if args.distributed:\n",
        "                reduced_loss = reduce_tensor(loss.data, args.world_size)\n",
        "                losses_m.update(reduced_loss.item(), input.size(0))\n",
        "\n",
        "            if args.local_rank == 0:\n",
        "                _logger.info(\n",
        "                    'Train: {} [{:>4d}/{} ({:>3.0f}%)]  '\n",
        "                    'Loss: {loss.val:>9.6f} ({loss.avg:>6.4f})  '\n",
        "                    'Time: {batch_time.val:.3f}s, {rate:>7.2f}/s  '\n",
        "                    '({batch_time.avg:.3f}s, {rate_avg:>7.2f}/s)  '\n",
        "                    'LR: {lr:.3e}  '\n",
        "                    'Data: {data_time.val:.3f} ({data_time.avg:.3f})'.format(\n",
        "                        epoch,\n",
        "                        batch_idx, len(loader),\n",
        "                        100. * batch_idx / last_idx,\n",
        "                        loss=losses_m,\n",
        "                        batch_time=batch_time_m,\n",
        "                        rate=input.size(0) * args.world_size / batch_time_m.val,\n",
        "                        rate_avg=input.size(0) * args.world_size / batch_time_m.avg,\n",
        "                        lr=lr,\n",
        "                        data_time=data_time_m))\n",
        "\n",
        "                if args.save_images and output_dir:\n",
        "                    torchvision.utils.save_image(\n",
        "                        input,\n",
        "                        os.path.join(output_dir, 'train-batch-%d.jpg' % batch_idx),\n",
        "                        padding=0,\n",
        "                        normalize=True)\n",
        "\n",
        "        if saver is not None and args.recovery_interval and (\n",
        "                last_batch or (batch_idx + 1) % args.recovery_interval == 0):\n",
        "            saver.save_recovery(epoch, batch_idx=batch_idx)\n",
        "\n",
        "        if lr_scheduler is not None:\n",
        "            lr_scheduler.step_update(num_updates=num_updates, metric=losses_m.avg)\n",
        "\n",
        "        end = time.time()\n",
        "        # end for\n",
        "\n",
        "    if hasattr(optimizer, 'sync_lookahead'):\n",
        "        optimizer.sync_lookahead()\n",
        "\n",
        "    return OrderedDict([('loss', losses_m.avg)])\n"
      ],
      "metadata": {
        "id": "gDFrznAXL4T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate(model, loader, loss_fn, args, amp_autocast=suppress, log_suffix=''):\n",
        "    batch_time_m = AverageMeter()\n",
        "    losses_m = AverageMeter()\n",
        "    top1_m = AverageMeter()\n",
        "    top5_m = AverageMeter()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    last_idx = len(loader) - 1\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (input, target) in enumerate(loader):\n",
        "            last_batch = batch_idx == last_idx\n",
        "            if not args.prefetcher:\n",
        "                input = input.cuda()\n",
        "                target = target.cuda()\n",
        "            if args.channels_last:\n",
        "                input = input.contiguous(memory_format=torch.channels_last)\n",
        "\n",
        "            with amp_autocast():\n",
        "                output = model(input)\n",
        "            if isinstance(output, (tuple, list)):\n",
        "                output = output[0]\n",
        "\n",
        "            # augmentation reduction\n",
        "            reduce_factor = args.tta\n",
        "            if reduce_factor > 1:\n",
        "                output = output.unfold(0, reduce_factor, reduce_factor).mean(dim=2)\n",
        "                target = target[0:target.size(0):reduce_factor]\n",
        "\n",
        "            loss = loss_fn(output, target)\n",
        "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "\n",
        "            if args.distributed:\n",
        "                reduced_loss = reduce_tensor(loss.data, args.world_size)\n",
        "                acc1 = reduce_tensor(acc1, args.world_size)\n",
        "                acc5 = reduce_tensor(acc5, args.world_size)\n",
        "            else:\n",
        "                reduced_loss = loss.data\n",
        "\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "            losses_m.update(reduced_loss.item(), input.size(0))\n",
        "            top1_m.update(acc1.item(), output.size(0))\n",
        "            top5_m.update(acc5.item(), output.size(0))\n",
        "\n",
        "            batch_time_m.update(time.time() - end)\n",
        "            end = time.time()\n",
        "            if args.local_rank == 0 and (last_batch or batch_idx % args.log_interval == 0):\n",
        "                log_name = 'Test' + log_suffix\n",
        "                _logger.info(\n",
        "                    '{0}: [{1:>4d}/{2}]  '\n",
        "                    'Time: {batch_time.val:.3f} ({batch_time.avg:.3f})  '\n",
        "                    'Loss: {loss.val:>7.4f} ({loss.avg:>6.4f})  '\n",
        "                    'Acc@1: {top1.val:>7.4f} ({top1.avg:>7.4f})  '\n",
        "                    'Acc@5: {top5.val:>7.4f} ({top5.avg:>7.4f})'.format(\n",
        "                        log_name, batch_idx, last_idx, batch_time=batch_time_m,\n",
        "                        loss=losses_m, top1=top1_m, top5=top5_m))\n",
        "\n",
        "    metrics = OrderedDict([('loss', losses_m.avg), ('top1', top1_m.avg), ('top5', top5_m.avg)])\n",
        "\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "HGdJVfSAL-3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMB7XJ7WCydz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f98205-61a9-47b6-84a2-784a80d718d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:train:Training with a single process on 1 GPUs.\n",
            "Training with a single process on 1 GPUs.\n",
            "INFO:train:Model resnet101 created, param count: 44549160\n",
            "Model resnet101 created, param count: 44549160\n",
            "INFO:timm.data.config:Data processing configuration for current model + dataset:\n",
            "Data processing configuration for current model + dataset:\n",
            "INFO:timm.data.config:\tinput_size: (3, 224, 224)\n",
            "\tinput_size: (3, 224, 224)\n",
            "INFO:timm.data.config:\tinterpolation: bicubic\n",
            "\tinterpolation: bicubic\n",
            "INFO:timm.data.config:\tmean: (0.485, 0.456, 0.406)\n",
            "\tmean: (0.485, 0.456, 0.406)\n",
            "INFO:timm.data.config:\tstd: (0.229, 0.224, 0.225)\n",
            "\tstd: (0.229, 0.224, 0.225)\n",
            "INFO:timm.data.config:\tcrop_pct: 0.95\n",
            "\tcrop_pct: 0.95\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model flops: 7817639424 input_size: [1, 3, 224, 224]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:train:AMP not enabled. Training in float32.\n",
            "AMP not enabled. Training in float32.\n",
            "INFO:train:Scheduled epochs: 10\n",
            "Scheduled epochs: 10\n",
            "INFO:train:Train: 0 [   0/296 (  0%)]  Loss:  6.882696 (6.8827)  Time: 36.461s,    0.88/s  (36.461s,    0.88/s)  LR: 1.000e-04  Data: 34.748 (34.748)\n",
            "Train: 0 [   0/296 (  0%)]  Loss:  6.882696 (6.8827)  Time: 36.461s,    0.88/s  (36.461s,    0.88/s)  LR: 1.000e-04  Data: 34.748 (34.748)\n",
            "INFO:train:Train: 0 [  50/296 ( 17%)]  Loss:  5.884432 (6.4201)  Time: 12.155s,    2.63/s  (12.123s,    2.64/s)  LR: 1.000e-04  Data: 11.581 (11.541)\n",
            "Train: 0 [  50/296 ( 17%)]  Loss:  5.884432 (6.4201)  Time: 12.155s,    2.63/s  (12.123s,    2.64/s)  LR: 1.000e-04  Data: 11.581 (11.541)\n",
            "INFO:train:Train: 0 [ 100/296 ( 34%)]  Loss:  4.788863 (5.8763)  Time: 12.379s,    2.58/s  (11.921s,    2.68/s)  LR: 1.000e-04  Data: 11.812 (11.345)\n",
            "Train: 0 [ 100/296 ( 34%)]  Loss:  4.788863 (5.8763)  Time: 12.379s,    2.58/s  (11.921s,    2.68/s)  LR: 1.000e-04  Data: 11.812 (11.345)\n",
            "INFO:train:Train: 0 [ 150/296 ( 51%)]  Loss:  3.879802 (5.3887)  Time: 12.628s,    2.53/s  (11.798s,    2.71/s)  LR: 1.000e-04  Data: 12.048 (11.222)\n",
            "Train: 0 [ 150/296 ( 51%)]  Loss:  3.879802 (5.3887)  Time: 12.628s,    2.53/s  (11.798s,    2.71/s)  LR: 1.000e-04  Data: 12.048 (11.222)\n",
            "INFO:train:Train: 0 [ 200/296 ( 68%)]  Loss:  3.558528 (4.9805)  Time: 10.821s,    2.96/s  (11.833s,    2.70/s)  LR: 1.000e-04  Data: 10.254 (11.260)\n",
            "Train: 0 [ 200/296 ( 68%)]  Loss:  3.558528 (4.9805)  Time: 10.821s,    2.96/s  (11.833s,    2.70/s)  LR: 1.000e-04  Data: 10.254 (11.260)\n",
            "INFO:train:Train: 0 [ 250/296 ( 85%)]  Loss:  3.418504 (4.6644)  Time: 12.227s,    2.62/s  (11.836s,    2.70/s)  LR: 1.000e-04  Data: 11.637 (11.262)\n",
            "Train: 0 [ 250/296 ( 85%)]  Loss:  3.418504 (4.6644)  Time: 12.227s,    2.62/s  (11.836s,    2.70/s)  LR: 1.000e-04  Data: 11.637 (11.262)\n",
            "INFO:train:Train: 0 [ 295/296 (100%)]  Loss:  3.150135 (4.4427)  Time: 0.545s,   58.70/s  (11.820s,    2.71/s)  LR: 1.000e-04  Data: 0.000 (11.246)\n",
            "Train: 0 [ 295/296 (100%)]  Loss:  3.150135 (4.4427)  Time: 0.545s,   58.70/s  (11.820s,    2.71/s)  LR: 1.000e-04  Data: 0.000 (11.246)\n",
            "INFO:train:Test: [   0/122]  Time: 22.522 (22.522)  Loss:  2.6665 (2.6665)  Acc@1: 28.1250 (28.1250)  Acc@5: 84.3750 (84.3750)\n",
            "Test: [   0/122]  Time: 22.522 (22.522)  Loss:  2.6665 (2.6665)  Acc@1: 28.1250 (28.1250)  Acc@5: 84.3750 (84.3750)\n",
            "INFO:train:Test: [  50/122]  Time: 12.730 (13.215)  Loss:  2.5668 (2.7286)  Acc@1: 12.5000 (14.9510)  Acc@5: 87.5000 (60.0490)\n",
            "Test: [  50/122]  Time: 12.730 (13.215)  Loss:  2.5668 (2.7286)  Acc@1: 12.5000 (14.9510)  Acc@5: 87.5000 (60.0490)\n",
            "INFO:train:Test: [ 100/122]  Time: 12.253 (12.916)  Loss:  2.5735 (2.6265)  Acc@1: 21.8750 (21.1324)  Acc@5: 84.3750 (71.0087)\n",
            "Test: [ 100/122]  Time: 12.253 (12.916)  Loss:  2.5735 (2.6265)  Acc@1: 21.8750 (21.1324)  Acc@5: 84.3750 (71.0087)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.573 (12.721)  Loss:  1.7950 (2.5476)  Acc@1: 71.4286 (27.1592)  Acc@5: 80.9524 (73.0191)\n",
            "Test: [ 122/122]  Time: 0.573 (12.721)  Loss:  1.7950 (2.5476)  Acc@1: 71.4286 (27.1592)  Acc@5: 80.9524 (73.0191)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 1 [   0/296 (  0%)]  Loss:  3.105312 (3.1053)  Time: 1.654s,   19.34/s  (1.654s,   19.34/s)  LR: 3.400e-03  Data: 1.061 (1.061)\n",
            "Train: 1 [   0/296 (  0%)]  Loss:  3.105312 (3.1053)  Time: 1.654s,   19.34/s  (1.654s,   19.34/s)  LR: 3.400e-03  Data: 1.061 (1.061)\n",
            "INFO:train:Train: 1 [  50/296 ( 17%)]  Loss:  2.733572 (2.9233)  Time: 1.053s,   30.39/s  (0.959s,   33.35/s)  LR: 3.400e-03  Data: 0.531 (0.427)\n",
            "Train: 1 [  50/296 ( 17%)]  Loss:  2.733572 (2.9233)  Time: 1.053s,   30.39/s  (0.959s,   33.35/s)  LR: 3.400e-03  Data: 0.531 (0.427)\n",
            "INFO:train:Train: 1 [ 100/296 ( 34%)]  Loss:  2.875779 (2.8928)  Time: 0.948s,   33.74/s  (0.944s,   33.89/s)  LR: 3.400e-03  Data: 0.412 (0.416)\n",
            "Train: 1 [ 100/296 ( 34%)]  Loss:  2.875779 (2.8928)  Time: 0.948s,   33.74/s  (0.944s,   33.89/s)  LR: 3.400e-03  Data: 0.412 (0.416)\n",
            "INFO:train:Train: 1 [ 150/296 ( 51%)]  Loss:  2.812840 (2.8605)  Time: 1.284s,   24.92/s  (0.944s,   33.90/s)  LR: 3.400e-03  Data: 0.762 (0.416)\n",
            "Train: 1 [ 150/296 ( 51%)]  Loss:  2.812840 (2.8605)  Time: 1.284s,   24.92/s  (0.944s,   33.90/s)  LR: 3.400e-03  Data: 0.762 (0.416)\n",
            "INFO:train:Train: 1 [ 200/296 ( 68%)]  Loss:  2.730822 (2.8353)  Time: 0.988s,   32.38/s  (0.943s,   33.92/s)  LR: 3.400e-03  Data: 0.462 (0.417)\n",
            "Train: 1 [ 200/296 ( 68%)]  Loss:  2.730822 (2.8353)  Time: 0.988s,   32.38/s  (0.943s,   33.92/s)  LR: 3.400e-03  Data: 0.462 (0.417)\n",
            "INFO:train:Train: 1 [ 250/296 ( 85%)]  Loss:  2.529229 (2.8197)  Time: 0.858s,   37.31/s  (0.945s,   33.87/s)  LR: 3.400e-03  Data: 0.336 (0.419)\n",
            "Train: 1 [ 250/296 ( 85%)]  Loss:  2.529229 (2.8197)  Time: 0.858s,   37.31/s  (0.945s,   33.87/s)  LR: 3.400e-03  Data: 0.336 (0.419)\n",
            "INFO:train:Train: 1 [ 295/296 (100%)]  Loss:  2.593697 (2.8010)  Time: 0.563s,   56.79/s  (0.941s,   33.99/s)  LR: 3.400e-03  Data: 0.001 (0.415)\n",
            "Train: 1 [ 295/296 (100%)]  Loss:  2.593697 (2.8010)  Time: 0.563s,   56.79/s  (0.941s,   33.99/s)  LR: 3.400e-03  Data: 0.001 (0.415)\n",
            "INFO:train:Test: [   0/122]  Time: 1.149 (1.149)  Loss:  1.6817 (1.6817)  Acc@1: 50.0000 (50.0000)  Acc@5: 90.6250 (90.6250)\n",
            "Test: [   0/122]  Time: 1.149 (1.149)  Loss:  1.6817 (1.6817)  Acc@1: 50.0000 (50.0000)  Acc@5: 90.6250 (90.6250)\n",
            "INFO:train:Test: [  50/122]  Time: 0.485 (0.521)  Loss:  2.4921 (2.0132)  Acc@1: 15.6250 (27.0833)  Acc@5: 65.6250 (84.1912)\n",
            "Test: [  50/122]  Time: 0.485 (0.521)  Loss:  2.4921 (2.0132)  Acc@1: 15.6250 (27.0833)  Acc@5: 65.6250 (84.1912)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.440 (0.548)  Loss:  2.4423 (1.8724)  Acc@1: 21.8750 (37.6856)  Acc@5: 68.7500 (86.1386)\n",
            "Test: [ 100/122]  Time: 0.440 (0.548)  Loss:  2.4423 (1.8724)  Acc@1: 21.8750 (37.6856)  Acc@5: 68.7500 (86.1386)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.113 (0.540)  Loss:  1.3394 (1.8573)  Acc@1: 66.6667 (39.7452)  Acc@5: 85.7143 (84.3312)\n",
            "Test: [ 122/122]  Time: 0.113 (0.540)  Loss:  1.3394 (1.8573)  Acc@1: 66.6667 (39.7452)  Acc@5: 85.7143 (84.3312)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 2 [   0/296 (  0%)]  Loss:  2.705170 (2.7052)  Time: 1.327s,   24.11/s  (1.327s,   24.11/s)  LR: 6.700e-03  Data: 0.763 (0.763)\n",
            "Train: 2 [   0/296 (  0%)]  Loss:  2.705170 (2.7052)  Time: 1.327s,   24.11/s  (1.327s,   24.11/s)  LR: 6.700e-03  Data: 0.763 (0.763)\n",
            "INFO:train:Train: 2 [  50/296 ( 17%)]  Loss:  2.787849 (2.7556)  Time: 0.823s,   38.88/s  (0.921s,   34.74/s)  LR: 6.700e-03  Data: 0.300 (0.395)\n",
            "Train: 2 [  50/296 ( 17%)]  Loss:  2.787849 (2.7556)  Time: 0.823s,   38.88/s  (0.921s,   34.74/s)  LR: 6.700e-03  Data: 0.300 (0.395)\n",
            "INFO:train:Train: 2 [ 100/296 ( 34%)]  Loss:  2.854008 (2.7233)  Time: 0.810s,   39.50/s  (0.915s,   34.96/s)  LR: 6.700e-03  Data: 0.285 (0.390)\n",
            "Train: 2 [ 100/296 ( 34%)]  Loss:  2.854008 (2.7233)  Time: 0.810s,   39.50/s  (0.915s,   34.96/s)  LR: 6.700e-03  Data: 0.285 (0.390)\n",
            "INFO:train:Train: 2 [ 150/296 ( 51%)]  Loss:  2.532514 (2.7231)  Time: 0.950s,   33.69/s  (0.920s,   34.78/s)  LR: 6.700e-03  Data: 0.427 (0.395)\n",
            "Train: 2 [ 150/296 ( 51%)]  Loss:  2.532514 (2.7231)  Time: 0.950s,   33.69/s  (0.920s,   34.78/s)  LR: 6.700e-03  Data: 0.427 (0.395)\n",
            "INFO:train:Train: 2 [ 200/296 ( 68%)]  Loss:  2.495659 (2.7006)  Time: 0.849s,   37.71/s  (0.920s,   34.79/s)  LR: 6.700e-03  Data: 0.324 (0.395)\n",
            "Train: 2 [ 200/296 ( 68%)]  Loss:  2.495659 (2.7006)  Time: 0.849s,   37.71/s  (0.920s,   34.79/s)  LR: 6.700e-03  Data: 0.324 (0.395)\n",
            "INFO:train:Train: 2 [ 250/296 ( 85%)]  Loss:  2.805115 (2.6804)  Time: 0.875s,   36.57/s  (0.917s,   34.90/s)  LR: 6.700e-03  Data: 0.351 (0.392)\n",
            "Train: 2 [ 250/296 ( 85%)]  Loss:  2.805115 (2.6804)  Time: 0.875s,   36.57/s  (0.917s,   34.90/s)  LR: 6.700e-03  Data: 0.351 (0.392)\n",
            "INFO:train:Train: 2 [ 295/296 (100%)]  Loss:  2.828555 (2.6665)  Time: 0.557s,   57.50/s  (0.917s,   34.90/s)  LR: 6.700e-03  Data: 0.000 (0.392)\n",
            "Train: 2 [ 295/296 (100%)]  Loss:  2.828555 (2.6665)  Time: 0.557s,   57.50/s  (0.917s,   34.90/s)  LR: 6.700e-03  Data: 0.000 (0.392)\n",
            "INFO:train:Test: [   0/122]  Time: 1.180 (1.180)  Loss:  1.0735 (1.0735)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [   0/122]  Time: 1.180 (1.180)  Loss:  1.0735 (1.0735)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "INFO:train:Test: [  50/122]  Time: 0.481 (0.530)  Loss:  2.0012 (2.0850)  Acc@1: 37.5000 (36.3971)  Acc@5: 78.1250 (79.9020)\n",
            "Test: [  50/122]  Time: 0.481 (0.530)  Loss:  2.0012 (2.0850)  Acc@1: 37.5000 (36.3971)  Acc@5: 78.1250 (79.9020)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.419 (0.554)  Loss:  1.7638 (1.9124)  Acc@1: 40.6250 (40.3775)  Acc@5: 93.7500 (84.9010)\n",
            "Test: [ 100/122]  Time: 0.419 (0.554)  Loss:  1.7638 (1.9124)  Acc@1: 40.6250 (40.3775)  Acc@5: 93.7500 (84.9010)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.113 (0.545)  Loss:  0.8514 (1.8105)  Acc@1: 76.1905 (43.5159)  Acc@5: 90.4762 (86.0127)\n",
            "Test: [ 122/122]  Time: 0.113 (0.545)  Loss:  0.8514 (1.8105)  Acc@1: 76.1905 (43.5159)  Acc@5: 90.4762 (86.0127)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 3 [   0/296 (  0%)]  Loss:  2.827700 (2.8277)  Time: 1.202s,   26.63/s  (1.202s,   26.63/s)  LR: 1.000e-02  Data: 0.677 (0.677)\n",
            "Train: 3 [   0/296 (  0%)]  Loss:  2.827700 (2.8277)  Time: 1.202s,   26.63/s  (1.202s,   26.63/s)  LR: 1.000e-02  Data: 0.677 (0.677)\n",
            "INFO:train:Train: 3 [  50/296 ( 17%)]  Loss:  2.898270 (2.6721)  Time: 1.200s,   26.67/s  (0.937s,   34.15/s)  LR: 1.000e-02  Data: 0.679 (0.411)\n",
            "Train: 3 [  50/296 ( 17%)]  Loss:  2.898270 (2.6721)  Time: 1.200s,   26.67/s  (0.937s,   34.15/s)  LR: 1.000e-02  Data: 0.679 (0.411)\n",
            "INFO:train:Train: 3 [ 100/296 ( 34%)]  Loss:  3.008947 (2.6370)  Time: 0.965s,   33.16/s  (0.923s,   34.66/s)  LR: 1.000e-02  Data: 0.441 (0.398)\n",
            "Train: 3 [ 100/296 ( 34%)]  Loss:  3.008947 (2.6370)  Time: 0.965s,   33.16/s  (0.923s,   34.66/s)  LR: 1.000e-02  Data: 0.441 (0.398)\n",
            "INFO:train:Train: 3 [ 150/296 ( 51%)]  Loss:  2.499753 (2.6470)  Time: 1.005s,   31.85/s  (0.922s,   34.70/s)  LR: 1.000e-02  Data: 0.483 (0.397)\n",
            "Train: 3 [ 150/296 ( 51%)]  Loss:  2.499753 (2.6470)  Time: 1.005s,   31.85/s  (0.922s,   34.70/s)  LR: 1.000e-02  Data: 0.483 (0.397)\n",
            "INFO:train:Train: 3 [ 200/296 ( 68%)]  Loss:  2.490807 (2.6372)  Time: 0.995s,   32.15/s  (0.921s,   34.76/s)  LR: 1.000e-02  Data: 0.465 (0.396)\n",
            "Train: 3 [ 200/296 ( 68%)]  Loss:  2.490807 (2.6372)  Time: 0.995s,   32.15/s  (0.921s,   34.76/s)  LR: 1.000e-02  Data: 0.465 (0.396)\n",
            "INFO:train:Train: 3 [ 250/296 ( 85%)]  Loss:  2.450824 (2.6182)  Time: 1.006s,   31.81/s  (0.920s,   34.77/s)  LR: 1.000e-02  Data: 0.480 (0.396)\n",
            "Train: 3 [ 250/296 ( 85%)]  Loss:  2.450824 (2.6182)  Time: 1.006s,   31.81/s  (0.920s,   34.77/s)  LR: 1.000e-02  Data: 0.480 (0.396)\n",
            "INFO:train:Train: 3 [ 295/296 (100%)]  Loss:  2.428497 (2.6107)  Time: 0.555s,   57.62/s  (0.917s,   34.89/s)  LR: 1.000e-02  Data: 0.000 (0.392)\n",
            "Train: 3 [ 295/296 (100%)]  Loss:  2.428497 (2.6107)  Time: 0.555s,   57.62/s  (0.917s,   34.89/s)  LR: 1.000e-02  Data: 0.000 (0.392)\n",
            "INFO:train:Test: [   0/122]  Time: 0.852 (0.852)  Loss:  1.6961 (1.6961)  Acc@1: 46.8750 (46.8750)  Acc@5: 87.5000 (87.5000)\n",
            "Test: [   0/122]  Time: 0.852 (0.852)  Loss:  1.6961 (1.6961)  Acc@1: 46.8750 (46.8750)  Acc@5: 87.5000 (87.5000)\n",
            "INFO:train:Test: [  50/122]  Time: 0.488 (0.535)  Loss:  1.2688 (1.8810)  Acc@1: 65.6250 (37.3162)  Acc@5: 93.7500 (89.1544)\n",
            "Test: [  50/122]  Time: 0.488 (0.535)  Loss:  1.2688 (1.8810)  Acc@1: 65.6250 (37.3162)  Acc@5: 93.7500 (89.1544)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.420 (0.555)  Loss:  2.3480 (1.6651)  Acc@1: 34.3750 (45.3589)  Acc@5: 81.2500 (91.2748)\n",
            "Test: [ 100/122]  Time: 0.420 (0.555)  Loss:  2.3480 (1.6651)  Acc@1: 34.3750 (45.3589)  Acc@5: 81.2500 (91.2748)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.113 (0.538)  Loss:  1.5903 (1.6944)  Acc@1: 52.3810 (46.0382)  Acc@5: 90.4762 (89.8854)\n",
            "Test: [ 122/122]  Time: 0.113 (0.538)  Loss:  1.5903 (1.6944)  Acc@1: 52.3810 (46.0382)  Acc@5: 90.4762 (89.8854)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 4 [   0/296 (  0%)]  Loss:  2.691518 (2.6915)  Time: 1.947s,   16.43/s  (1.947s,   16.43/s)  LR: 1.000e-02  Data: 1.358 (1.358)\n",
            "Train: 4 [   0/296 (  0%)]  Loss:  2.691518 (2.6915)  Time: 1.947s,   16.43/s  (1.947s,   16.43/s)  LR: 1.000e-02  Data: 1.358 (1.358)\n",
            "INFO:train:Train: 4 [  50/296 ( 17%)]  Loss:  2.623461 (2.5824)  Time: 0.937s,   34.14/s  (0.929s,   34.46/s)  LR: 1.000e-02  Data: 0.413 (0.402)\n",
            "Train: 4 [  50/296 ( 17%)]  Loss:  2.623461 (2.5824)  Time: 0.937s,   34.14/s  (0.929s,   34.46/s)  LR: 1.000e-02  Data: 0.413 (0.402)\n",
            "INFO:train:Train: 4 [ 100/296 ( 34%)]  Loss:  2.952631 (2.5650)  Time: 1.014s,   31.56/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.488 (0.390)\n",
            "Train: 4 [ 100/296 ( 34%)]  Loss:  2.952631 (2.5650)  Time: 1.014s,   31.56/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.488 (0.390)\n",
            "INFO:train:Train: 4 [ 150/296 ( 51%)]  Loss:  2.181253 (2.5503)  Time: 0.973s,   32.89/s  (0.913s,   35.06/s)  LR: 1.000e-02  Data: 0.446 (0.388)\n",
            "Train: 4 [ 150/296 ( 51%)]  Loss:  2.181253 (2.5503)  Time: 0.973s,   32.89/s  (0.913s,   35.06/s)  LR: 1.000e-02  Data: 0.446 (0.388)\n",
            "INFO:train:Train: 4 [ 200/296 ( 68%)]  Loss:  2.456050 (2.5380)  Time: 0.950s,   33.68/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.426 (0.391)\n",
            "Train: 4 [ 200/296 ( 68%)]  Loss:  2.456050 (2.5380)  Time: 0.950s,   33.68/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.426 (0.391)\n",
            "INFO:train:Train: 4 [ 250/296 ( 85%)]  Loss:  2.568549 (2.5328)  Time: 0.999s,   32.02/s  (0.918s,   34.86/s)  LR: 1.000e-02  Data: 0.474 (0.393)\n",
            "Train: 4 [ 250/296 ( 85%)]  Loss:  2.568549 (2.5328)  Time: 0.999s,   32.02/s  (0.918s,   34.86/s)  LR: 1.000e-02  Data: 0.474 (0.393)\n",
            "INFO:train:Train: 4 [ 295/296 (100%)]  Loss:  2.748955 (2.5223)  Time: 0.558s,   57.30/s  (0.917s,   34.89/s)  LR: 1.000e-02  Data: 0.000 (0.392)\n",
            "Train: 4 [ 295/296 (100%)]  Loss:  2.748955 (2.5223)  Time: 0.558s,   57.30/s  (0.917s,   34.89/s)  LR: 1.000e-02  Data: 0.000 (0.392)\n",
            "INFO:train:Test: [   0/122]  Time: 0.902 (0.902)  Loss:  1.3758 (1.3758)  Acc@1: 53.1250 (53.1250)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [   0/122]  Time: 0.902 (0.902)  Loss:  1.3758 (1.3758)  Acc@1: 53.1250 (53.1250)  Acc@5: 100.0000 (100.0000)\n",
            "INFO:train:Test: [  50/122]  Time: 0.482 (0.528)  Loss:  2.3296 (1.6040)  Acc@1: 21.8750 (47.3039)  Acc@5: 87.5000 (94.3627)\n",
            "Test: [  50/122]  Time: 0.482 (0.528)  Loss:  2.3296 (1.6040)  Acc@1: 21.8750 (47.3039)  Acc@5: 87.5000 (94.3627)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.516 (0.546)  Loss:  1.6317 (1.6103)  Acc@1: 53.1250 (48.5458)  Acc@5: 93.7500 (92.2030)\n",
            "Test: [ 100/122]  Time: 0.516 (0.546)  Loss:  1.6317 (1.6103)  Acc@1: 53.1250 (48.5458)  Acc@5: 93.7500 (92.2030)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.114 (0.530)  Loss:  0.9110 (1.5608)  Acc@1: 61.9048 (49.9873)  Acc@5: 100.0000 (92.1529)\n",
            "Test: [ 122/122]  Time: 0.114 (0.530)  Loss:  0.9110 (1.5608)  Acc@1: 61.9048 (49.9873)  Acc@5: 100.0000 (92.1529)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 5 [   0/296 (  0%)]  Loss:  2.542377 (2.5424)  Time: 1.391s,   23.01/s  (1.391s,   23.01/s)  LR: 1.000e-02  Data: 0.861 (0.861)\n",
            "Train: 5 [   0/296 (  0%)]  Loss:  2.542377 (2.5424)  Time: 1.391s,   23.01/s  (1.391s,   23.01/s)  LR: 1.000e-02  Data: 0.861 (0.861)\n",
            "INFO:train:Train: 5 [  50/296 ( 17%)]  Loss:  2.252735 (2.4678)  Time: 0.874s,   36.60/s  (0.930s,   34.40/s)  LR: 1.000e-02  Data: 0.347 (0.405)\n",
            "Train: 5 [  50/296 ( 17%)]  Loss:  2.252735 (2.4678)  Time: 0.874s,   36.60/s  (0.930s,   34.40/s)  LR: 1.000e-02  Data: 0.347 (0.405)\n",
            "INFO:train:Train: 5 [ 100/296 ( 34%)]  Loss:  2.589622 (2.4569)  Time: 0.840s,   38.09/s  (0.920s,   34.77/s)  LR: 1.000e-02  Data: 0.316 (0.396)\n",
            "Train: 5 [ 100/296 ( 34%)]  Loss:  2.589622 (2.4569)  Time: 0.840s,   38.09/s  (0.920s,   34.77/s)  LR: 1.000e-02  Data: 0.316 (0.396)\n",
            "INFO:train:Train: 5 [ 150/296 ( 51%)]  Loss:  2.437994 (2.4546)  Time: 0.852s,   37.57/s  (0.920s,   34.79/s)  LR: 1.000e-02  Data: 0.329 (0.396)\n",
            "Train: 5 [ 150/296 ( 51%)]  Loss:  2.437994 (2.4546)  Time: 0.852s,   37.57/s  (0.920s,   34.79/s)  LR: 1.000e-02  Data: 0.329 (0.396)\n",
            "INFO:train:Train: 5 [ 200/296 ( 68%)]  Loss:  2.417598 (2.4613)  Time: 0.868s,   36.88/s  (0.917s,   34.91/s)  LR: 1.000e-02  Data: 0.347 (0.392)\n",
            "Train: 5 [ 200/296 ( 68%)]  Loss:  2.417598 (2.4613)  Time: 0.868s,   36.88/s  (0.917s,   34.91/s)  LR: 1.000e-02  Data: 0.347 (0.392)\n",
            "INFO:train:Train: 5 [ 250/296 ( 85%)]  Loss:  2.658482 (2.4548)  Time: 1.009s,   31.72/s  (0.916s,   34.94/s)  LR: 1.000e-02  Data: 0.483 (0.392)\n",
            "Train: 5 [ 250/296 ( 85%)]  Loss:  2.658482 (2.4548)  Time: 1.009s,   31.72/s  (0.916s,   34.94/s)  LR: 1.000e-02  Data: 0.483 (0.392)\n",
            "INFO:train:Train: 5 [ 295/296 (100%)]  Loss:  2.570380 (2.4486)  Time: 0.561s,   57.01/s  (0.916s,   34.92/s)  LR: 1.000e-02  Data: 0.000 (0.392)\n",
            "Train: 5 [ 295/296 (100%)]  Loss:  2.570380 (2.4486)  Time: 0.561s,   57.01/s  (0.916s,   34.92/s)  LR: 1.000e-02  Data: 0.000 (0.392)\n",
            "INFO:train:Test: [   0/122]  Time: 0.870 (0.870)  Loss:  1.1451 (1.1451)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [   0/122]  Time: 0.870 (0.870)  Loss:  1.1451 (1.1451)  Acc@1: 68.7500 (68.7500)  Acc@5: 100.0000 (100.0000)\n",
            "INFO:train:Test: [  50/122]  Time: 0.615 (0.518)  Loss:  0.8813 (1.3511)  Acc@1: 81.2500 (58.0882)  Acc@5: 93.7500 (95.4657)\n",
            "Test: [  50/122]  Time: 0.615 (0.518)  Loss:  0.8813 (1.3511)  Acc@1: 81.2500 (58.0882)  Acc@5: 93.7500 (95.4657)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.449 (0.537)  Loss:  2.2268 (1.4649)  Acc@1: 34.3750 (53.2797)  Acc@5: 75.0000 (93.3168)\n",
            "Test: [ 100/122]  Time: 0.449 (0.537)  Loss:  2.2268 (1.4649)  Acc@1: 34.3750 (53.2797)  Acc@5: 75.0000 (93.3168)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.113 (0.529)  Loss:  1.3601 (1.5229)  Acc@1: 47.6190 (51.5414)  Acc@5: 90.4762 (91.9490)\n",
            "Test: [ 122/122]  Time: 0.113 (0.529)  Loss:  1.3601 (1.5229)  Acc@1: 47.6190 (51.5414)  Acc@5: 90.4762 (91.9490)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 6 [   0/296 (  0%)]  Loss:  2.117280 (2.1173)  Time: 1.208s,   26.48/s  (1.208s,   26.48/s)  LR: 1.000e-02  Data: 0.685 (0.685)\n",
            "Train: 6 [   0/296 (  0%)]  Loss:  2.117280 (2.1173)  Time: 1.208s,   26.48/s  (1.208s,   26.48/s)  LR: 1.000e-02  Data: 0.685 (0.685)\n",
            "INFO:train:Train: 6 [  50/296 ( 17%)]  Loss:  2.141742 (2.4337)  Time: 0.907s,   35.27/s  (0.921s,   34.76/s)  LR: 1.000e-02  Data: 0.386 (0.396)\n",
            "Train: 6 [  50/296 ( 17%)]  Loss:  2.141742 (2.4337)  Time: 0.907s,   35.27/s  (0.921s,   34.76/s)  LR: 1.000e-02  Data: 0.386 (0.396)\n",
            "INFO:train:Train: 6 [ 100/296 ( 34%)]  Loss:  2.443827 (2.4174)  Time: 0.839s,   38.15/s  (0.914s,   35.00/s)  LR: 1.000e-02  Data: 0.312 (0.390)\n",
            "Train: 6 [ 100/296 ( 34%)]  Loss:  2.443827 (2.4174)  Time: 0.839s,   38.15/s  (0.914s,   35.00/s)  LR: 1.000e-02  Data: 0.312 (0.390)\n",
            "INFO:train:Train: 6 [ 150/296 ( 51%)]  Loss:  2.461748 (2.4077)  Time: 0.892s,   35.86/s  (0.910s,   35.18/s)  LR: 1.000e-02  Data: 0.370 (0.385)\n",
            "Train: 6 [ 150/296 ( 51%)]  Loss:  2.461748 (2.4077)  Time: 0.892s,   35.86/s  (0.910s,   35.18/s)  LR: 1.000e-02  Data: 0.370 (0.385)\n",
            "INFO:train:Train: 6 [ 200/296 ( 68%)]  Loss:  2.298093 (2.4085)  Time: 0.937s,   34.16/s  (0.914s,   34.99/s)  LR: 1.000e-02  Data: 0.417 (0.390)\n",
            "Train: 6 [ 200/296 ( 68%)]  Loss:  2.298093 (2.4085)  Time: 0.937s,   34.16/s  (0.914s,   34.99/s)  LR: 1.000e-02  Data: 0.417 (0.390)\n",
            "INFO:train:Train: 6 [ 250/296 ( 85%)]  Loss:  2.420057 (2.4048)  Time: 0.834s,   38.36/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.310 (0.391)\n",
            "Train: 6 [ 250/296 ( 85%)]  Loss:  2.420057 (2.4048)  Time: 0.834s,   38.36/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.310 (0.391)\n",
            "INFO:train:Train: 6 [ 295/296 (100%)]  Loss:  2.140485 (2.4007)  Time: 0.556s,   57.51/s  (0.915s,   34.96/s)  LR: 1.000e-02  Data: 0.000 (0.391)\n",
            "Train: 6 [ 295/296 (100%)]  Loss:  2.140485 (2.4007)  Time: 0.556s,   57.51/s  (0.915s,   34.96/s)  LR: 1.000e-02  Data: 0.000 (0.391)\n",
            "INFO:train:Test: [   0/122]  Time: 1.128 (1.128)  Loss:  1.5998 (1.5998)  Acc@1: 40.6250 (40.6250)  Acc@5: 93.7500 (93.7500)\n",
            "Test: [   0/122]  Time: 1.128 (1.128)  Loss:  1.5998 (1.5998)  Acc@1: 40.6250 (40.6250)  Acc@5: 93.7500 (93.7500)\n",
            "INFO:train:Test: [  50/122]  Time: 0.476 (0.506)  Loss:  0.6888 (1.5652)  Acc@1: 81.2500 (50.6740)  Acc@5: 100.0000 (92.8309)\n",
            "Test: [  50/122]  Time: 0.476 (0.506)  Loss:  0.6888 (1.5652)  Acc@1: 81.2500 (50.6740)  Acc@5: 100.0000 (92.8309)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.419 (0.538)  Loss:  1.4591 (1.4849)  Acc@1: 71.8750 (52.4443)  Acc@5: 96.8750 (94.2141)\n",
            "Test: [ 100/122]  Time: 0.419 (0.538)  Loss:  1.4591 (1.4849)  Acc@1: 71.8750 (52.4443)  Acc@5: 96.8750 (94.2141)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.114 (0.533)  Loss:  1.4828 (1.4771)  Acc@1: 71.4286 (54.4968)  Acc@5: 80.9524 (93.1720)\n",
            "Test: [ 122/122]  Time: 0.114 (0.533)  Loss:  1.4828 (1.4771)  Acc@1: 71.4286 (54.4968)  Acc@5: 80.9524 (93.1720)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 7 [   0/296 (  0%)]  Loss:  2.674390 (2.6744)  Time: 1.436s,   22.29/s  (1.436s,   22.29/s)  LR: 1.000e-02  Data: 0.860 (0.860)\n",
            "Train: 7 [   0/296 (  0%)]  Loss:  2.674390 (2.6744)  Time: 1.436s,   22.29/s  (1.436s,   22.29/s)  LR: 1.000e-02  Data: 0.860 (0.860)\n",
            "INFO:train:Train: 7 [  50/296 ( 17%)]  Loss:  2.193932 (2.3769)  Time: 0.853s,   37.51/s  (0.910s,   35.17/s)  LR: 1.000e-02  Data: 0.331 (0.385)\n",
            "Train: 7 [  50/296 ( 17%)]  Loss:  2.193932 (2.3769)  Time: 0.853s,   37.51/s  (0.910s,   35.17/s)  LR: 1.000e-02  Data: 0.331 (0.385)\n",
            "INFO:train:Train: 7 [ 100/296 ( 34%)]  Loss:  2.264287 (2.3889)  Time: 0.847s,   37.79/s  (0.919s,   34.82/s)  LR: 1.000e-02  Data: 0.321 (0.395)\n",
            "Train: 7 [ 100/296 ( 34%)]  Loss:  2.264287 (2.3889)  Time: 0.847s,   37.79/s  (0.919s,   34.82/s)  LR: 1.000e-02  Data: 0.321 (0.395)\n",
            "INFO:train:Train: 7 [ 150/296 ( 51%)]  Loss:  2.012927 (2.3740)  Time: 0.879s,   36.39/s  (0.917s,   34.89/s)  LR: 1.000e-02  Data: 0.358 (0.393)\n",
            "Train: 7 [ 150/296 ( 51%)]  Loss:  2.012927 (2.3740)  Time: 0.879s,   36.39/s  (0.917s,   34.89/s)  LR: 1.000e-02  Data: 0.358 (0.393)\n",
            "INFO:train:Train: 7 [ 200/296 ( 68%)]  Loss:  2.755336 (2.3615)  Time: 0.848s,   37.73/s  (0.918s,   34.88/s)  LR: 1.000e-02  Data: 0.325 (0.393)\n",
            "Train: 7 [ 200/296 ( 68%)]  Loss:  2.755336 (2.3615)  Time: 0.848s,   37.73/s  (0.918s,   34.88/s)  LR: 1.000e-02  Data: 0.325 (0.393)\n",
            "INFO:train:Train: 7 [ 250/296 ( 85%)]  Loss:  2.427542 (2.3528)  Time: 0.812s,   39.39/s  (0.918s,   34.87/s)  LR: 1.000e-02  Data: 0.287 (0.393)\n",
            "Train: 7 [ 250/296 ( 85%)]  Loss:  2.427542 (2.3528)  Time: 0.812s,   39.39/s  (0.918s,   34.87/s)  LR: 1.000e-02  Data: 0.287 (0.393)\n",
            "INFO:train:Train: 7 [ 295/296 (100%)]  Loss:  2.378900 (2.3587)  Time: 0.559s,   57.27/s  (0.913s,   35.05/s)  LR: 1.000e-02  Data: 0.001 (0.389)\n",
            "Train: 7 [ 295/296 (100%)]  Loss:  2.378900 (2.3587)  Time: 0.559s,   57.27/s  (0.913s,   35.05/s)  LR: 1.000e-02  Data: 0.001 (0.389)\n",
            "INFO:train:Test: [   0/122]  Time: 1.177 (1.177)  Loss:  1.0045 (1.0045)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [   0/122]  Time: 1.177 (1.177)  Loss:  1.0045 (1.0045)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "INFO:train:Test: [  50/122]  Time: 0.492 (0.528)  Loss:  1.3873 (1.6823)  Acc@1: 59.3750 (45.8333)  Acc@5: 93.7500 (90.0735)\n",
            "Test: [  50/122]  Time: 0.492 (0.528)  Loss:  1.3873 (1.6823)  Acc@1: 59.3750 (45.8333)  Acc@5: 93.7500 (90.0735)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.417 (0.548)  Loss:  1.7622 (1.4760)  Acc@1: 43.7500 (53.0631)  Acc@5: 96.8750 (92.5124)\n",
            "Test: [ 100/122]  Time: 0.417 (0.548)  Loss:  1.7622 (1.4760)  Acc@1: 43.7500 (53.0631)  Acc@5: 96.8750 (92.5124)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.113 (0.539)  Loss:  1.4826 (1.4773)  Acc@1: 57.1429 (54.0382)  Acc@5: 85.7143 (92.2293)\n",
            "Test: [ 122/122]  Time: 0.113 (0.539)  Loss:  1.4826 (1.4773)  Acc@1: 57.1429 (54.0382)  Acc@5: 85.7143 (92.2293)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-7.pth.tar', 54.03821655759386)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-7.pth.tar', 54.03821655759386)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 8 [   0/296 (  0%)]  Loss:  2.393579 (2.3936)  Time: 1.239s,   25.82/s  (1.239s,   25.82/s)  LR: 1.000e-02  Data: 0.677 (0.677)\n",
            "Train: 8 [   0/296 (  0%)]  Loss:  2.393579 (2.3936)  Time: 1.239s,   25.82/s  (1.239s,   25.82/s)  LR: 1.000e-02  Data: 0.677 (0.677)\n",
            "INFO:train:Train: 8 [  50/296 ( 17%)]  Loss:  2.434315 (2.3103)  Time: 0.852s,   37.54/s  (0.921s,   34.74/s)  LR: 1.000e-02  Data: 0.332 (0.395)\n",
            "Train: 8 [  50/296 ( 17%)]  Loss:  2.434315 (2.3103)  Time: 0.852s,   37.54/s  (0.921s,   34.74/s)  LR: 1.000e-02  Data: 0.332 (0.395)\n",
            "INFO:train:Train: 8 [ 100/296 ( 34%)]  Loss:  2.653476 (2.3069)  Time: 0.979s,   32.67/s  (0.917s,   34.88/s)  LR: 1.000e-02  Data: 0.452 (0.393)\n",
            "Train: 8 [ 100/296 ( 34%)]  Loss:  2.653476 (2.3069)  Time: 0.979s,   32.67/s  (0.917s,   34.88/s)  LR: 1.000e-02  Data: 0.452 (0.393)\n",
            "INFO:train:Train: 8 [ 150/296 ( 51%)]  Loss:  2.341359 (2.3019)  Time: 1.009s,   31.72/s  (0.916s,   34.93/s)  LR: 1.000e-02  Data: 0.484 (0.391)\n",
            "Train: 8 [ 150/296 ( 51%)]  Loss:  2.341359 (2.3019)  Time: 1.009s,   31.72/s  (0.916s,   34.93/s)  LR: 1.000e-02  Data: 0.484 (0.391)\n",
            "INFO:train:Train: 8 [ 200/296 ( 68%)]  Loss:  2.453027 (2.3030)  Time: 0.936s,   34.19/s  (0.915s,   34.99/s)  LR: 1.000e-02  Data: 0.409 (0.390)\n",
            "Train: 8 [ 200/296 ( 68%)]  Loss:  2.453027 (2.3030)  Time: 0.936s,   34.19/s  (0.915s,   34.99/s)  LR: 1.000e-02  Data: 0.409 (0.390)\n",
            "INFO:train:Train: 8 [ 250/296 ( 85%)]  Loss:  2.185845 (2.3107)  Time: 0.975s,   32.81/s  (0.912s,   35.09/s)  LR: 1.000e-02  Data: 0.448 (0.388)\n",
            "Train: 8 [ 250/296 ( 85%)]  Loss:  2.185845 (2.3107)  Time: 0.975s,   32.81/s  (0.912s,   35.09/s)  LR: 1.000e-02  Data: 0.448 (0.388)\n",
            "INFO:train:Train: 8 [ 295/296 (100%)]  Loss:  2.063064 (2.3065)  Time: 0.559s,   57.22/s  (0.911s,   35.12/s)  LR: 1.000e-02  Data: 0.000 (0.387)\n",
            "Train: 8 [ 295/296 (100%)]  Loss:  2.063064 (2.3065)  Time: 0.559s,   57.22/s  (0.911s,   35.12/s)  LR: 1.000e-02  Data: 0.000 (0.387)\n",
            "INFO:train:Test: [   0/122]  Time: 0.844 (0.844)  Loss:  1.0025 (1.0025)  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)\n",
            "Test: [   0/122]  Time: 0.844 (0.844)  Loss:  1.0025 (1.0025)  Acc@1: 84.3750 (84.3750)  Acc@5: 96.8750 (96.8750)\n",
            "INFO:train:Test: [  50/122]  Time: 0.476 (0.528)  Loss:  0.9274 (1.4863)  Acc@1: 71.8750 (55.0858)  Acc@5: 100.0000 (94.0564)\n",
            "Test: [  50/122]  Time: 0.476 (0.528)  Loss:  0.9274 (1.4863)  Acc@1: 71.8750 (55.0858)  Acc@5: 100.0000 (94.0564)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.413 (0.547)  Loss:  1.7953 (1.3456)  Acc@1: 50.0000 (60.0557)  Acc@5: 96.8750 (94.8020)\n",
            "Test: [ 100/122]  Time: 0.413 (0.547)  Loss:  1.7953 (1.3456)  Acc@1: 50.0000 (60.0557)  Acc@5: 96.8750 (94.8020)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.113 (0.530)  Loss:  1.1309 (1.3361)  Acc@1: 61.9048 (60.9936)  Acc@5: 95.2381 (94.4459)\n",
            "Test: [ 122/122]  Time: 0.113 (0.530)  Loss:  1.1309 (1.3361)  Acc@1: 61.9048 (60.9936)  Acc@5: 95.2381 (94.4459)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-8.pth.tar', 60.9936305751922)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-7.pth.tar', 54.03821655759386)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-8.pth.tar', 60.9936305751922)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-7.pth.tar', 54.03821655759386)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:Train: 9 [   0/296 (  0%)]  Loss:  2.263051 (2.2631)  Time: 1.753s,   18.25/s  (1.753s,   18.25/s)  LR: 1.000e-02  Data: 1.194 (1.194)\n",
            "Train: 9 [   0/296 (  0%)]  Loss:  2.263051 (2.2631)  Time: 1.753s,   18.25/s  (1.753s,   18.25/s)  LR: 1.000e-02  Data: 1.194 (1.194)\n",
            "INFO:train:Train: 9 [  50/296 ( 17%)]  Loss:  2.497949 (2.2738)  Time: 1.192s,   26.86/s  (0.926s,   34.56/s)  LR: 1.000e-02  Data: 0.670 (0.401)\n",
            "Train: 9 [  50/296 ( 17%)]  Loss:  2.497949 (2.2738)  Time: 1.192s,   26.86/s  (0.926s,   34.56/s)  LR: 1.000e-02  Data: 0.670 (0.401)\n",
            "INFO:train:Train: 9 [ 100/296 ( 34%)]  Loss:  2.085532 (2.2792)  Time: 1.007s,   31.77/s  (0.919s,   34.81/s)  LR: 1.000e-02  Data: 0.484 (0.395)\n",
            "Train: 9 [ 100/296 ( 34%)]  Loss:  2.085532 (2.2792)  Time: 1.007s,   31.77/s  (0.919s,   34.81/s)  LR: 1.000e-02  Data: 0.484 (0.395)\n",
            "INFO:train:Train: 9 [ 150/296 ( 51%)]  Loss:  2.079120 (2.2850)  Time: 0.850s,   37.65/s  (0.911s,   35.12/s)  LR: 1.000e-02  Data: 0.324 (0.387)\n",
            "Train: 9 [ 150/296 ( 51%)]  Loss:  2.079120 (2.2850)  Time: 0.850s,   37.65/s  (0.911s,   35.12/s)  LR: 1.000e-02  Data: 0.324 (0.387)\n",
            "INFO:train:Train: 9 [ 200/296 ( 68%)]  Loss:  2.584216 (2.2919)  Time: 0.883s,   36.22/s  (0.916s,   34.93/s)  LR: 1.000e-02  Data: 0.358 (0.392)\n",
            "Train: 9 [ 200/296 ( 68%)]  Loss:  2.584216 (2.2919)  Time: 0.883s,   36.22/s  (0.916s,   34.93/s)  LR: 1.000e-02  Data: 0.358 (0.392)\n",
            "INFO:train:Train: 9 [ 250/296 ( 85%)]  Loss:  2.113848 (2.2842)  Time: 0.857s,   37.35/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.332 (0.391)\n",
            "Train: 9 [ 250/296 ( 85%)]  Loss:  2.113848 (2.2842)  Time: 0.857s,   37.35/s  (0.916s,   34.95/s)  LR: 1.000e-02  Data: 0.332 (0.391)\n",
            "INFO:train:Train: 9 [ 295/296 (100%)]  Loss:  2.212912 (2.2798)  Time: 0.559s,   57.23/s  (0.915s,   34.99/s)  LR: 1.000e-02  Data: 0.000 (0.390)\n",
            "Train: 9 [ 295/296 (100%)]  Loss:  2.212912 (2.2798)  Time: 0.559s,   57.23/s  (0.915s,   34.99/s)  LR: 1.000e-02  Data: 0.000 (0.390)\n",
            "INFO:train:Test: [   0/122]  Time: 0.841 (0.841)  Loss:  0.6875 (0.6875)  Acc@1: 78.1250 (78.1250)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [   0/122]  Time: 0.841 (0.841)  Loss:  0.6875 (0.6875)  Acc@1: 78.1250 (78.1250)  Acc@5: 100.0000 (100.0000)\n",
            "INFO:train:Test: [  50/122]  Time: 0.604 (0.531)  Loss:  0.8218 (1.1807)  Acc@1: 81.2500 (62.0711)  Acc@5: 93.7500 (97.0588)\n",
            "Test: [  50/122]  Time: 0.604 (0.531)  Loss:  0.8218 (1.1807)  Acc@1: 81.2500 (62.0711)  Acc@5: 93.7500 (97.0588)\n",
            "INFO:train:Test: [ 100/122]  Time: 0.529 (0.544)  Loss:  1.9612 (1.2333)  Acc@1: 43.7500 (61.9740)  Acc@5: 93.7500 (95.2042)\n",
            "Test: [ 100/122]  Time: 0.529 (0.544)  Loss:  1.9612 (1.2333)  Acc@1: 43.7500 (61.9740)  Acc@5: 93.7500 (95.2042)\n",
            "INFO:train:Test: [ 122/122]  Time: 0.114 (0.531)  Loss:  1.5526 (1.3112)  Acc@1: 57.1429 (60.3822)  Acc@5: 95.2381 (94.2166)\n",
            "Test: [ 122/122]  Time: 0.114 (0.531)  Loss:  1.5526 (1.3112)  Acc@1: 57.1429 (60.3822)  Acc@5: 95.2381 (94.2166)\n",
            "INFO:timm.utils.checkpoint_saver:Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-8.pth.tar', 60.9936305751922)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-9.pth.tar', 60.382165602179846)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-7.pth.tar', 54.03821655759386)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "Current checkpoints:\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-8.pth.tar', 60.9936305751922)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-9.pth.tar', 60.382165602179846)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-6.pth.tar', 54.496815298286975)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-7.pth.tar', 54.03821655759386)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-5.pth.tar', 51.54140128166053)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-4.pth.tar', 49.98726114844061)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-3.pth.tar', 46.03821657314422)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-2.pth.tar', 43.51592356299139)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-1.pth.tar', 39.745222916329745)\n",
            " ('./output/train/20230425-023149-resnet101-224/checkpoint-0.pth.tar', 27.15923568045258)\n",
            "\n",
            "INFO:train:*** Best metric: 60.9936305751922 (epoch 8)\n",
            "*** Best metric: 60.9936305751922 (epoch 8)\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5gnTCS8CygY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}